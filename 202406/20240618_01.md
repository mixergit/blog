## PG PK MySQL/Oracle/国产.又干输了? 教你几招性能PK的“作弊技巧”! 让你的数据库也能遥遥领先     
                     
### 作者                                            
digoal                                            
                                            
### 日期                                            
2024-06-18                                 
                                            
### 标签                           
PostgreSQL , PolarDB , DuckDB , PK , 作弊手段 , 性能  
                                            
----                                            
                                            
## 背景      
  
  
PG PK MySQL/Oracle/国产..., 假设硬件环境一样, 如何取得更大胜算? 教你几招“作弊技巧”!    
  
“作弊技巧”以tpch, 高并发小事务, 批量导入三个PK场景为例.    
  
PS: 很多场景是PG的强项, 担心被人说胜之不武, 可以发挥插件和索引人无我有功能的场景, 如模糊搜索、GIS、数组标签、向量相似等. 看我宝典:   
- [《2023-PostgreSQL Docker镜像学习环境 ARM64版, 已集成热门插件和工具》](../202308/20230814_02.md)       
- [《2023-PostgreSQL Docker镜像学习环境 AMD64版, 已集成热门插件和工具》](../202307/20230710_03.md)    
- [《2017-PostgreSQL 应用场景实践 - 适合架构师与业务开发者》](../201805/20180524_02.md)    
- [《2020-PostgreSQL+MySQL 联合解决方案课程 - 适合架构师与业务开发者》](../202001/20200118_02.md)    
- [《2020-PostgreSQL 应用场景最佳实践 - 适合架构师与业务开发者》](../202009/20200903_02.md)    
- [《2021-重新发现PG之美 系列 - 适合架构师与业务开发者》](../202105/20210526_02.md)    
- [《Oracle DBA 增值+转型 PostgreSQL 学习方法、路径》](../201804/20180425_01.md)     
- [《PostgreSQL、Greenplum 技术+108个场景结合最佳实践《如来神掌》》](../201706/20170601_02.md)      
  
既然是作弊, 有一些是有丢数据库风险/数据库不一致风险的, 有一些是属于耍流氓的, 所以千万不要让对手知道, 否则被打0分可别怪我. 你有坚硬的商务关系当我没说, 算我"助纣为虐"了.    
  
## TPCH  
详细操作请参考: [《PG被DuckDB碾压,该反省哪些方面? DuckDB v0.10.3 在Macmini 2023款上的tpch性能表现如何? PostgreSQL使用duckdb_fdw 的tpch加速性能表现如何?》](../202405/20240525_01.md)    
  
要大幅度提升OLTP数据库的tpch性能, 这不是扯淡吗? 改造优化器、存储、向量化是必须滴, 不过PG还真可以作弊, 例如:  
- 1、把数据库装进parquet  
- 2、把结构装进duckdb  
- 3、把tpch的22条query做成视图  
- 4、用fdw调用duckdb  
  
搞定, 一气呵成, 大概能提升个40几倍的性能吧.  别让人知道, 你这是在耍流氓.    
  
补充一个作弊技巧: 偷换执行计划, 甚至把用户请求的SQL自动改写成其他SQL, 方法：   
- [《PostgreSQL Oracle 兼容性之 - SQL OUTLINE插件sr_plan (保存、篡改、固定 执行计划)》](../201702/20170228_01.md)  
- [《PostgreSQL 执行计划篡改、SQL rule自动改写SQL(query rewrite)、自动触发额外动作 - 指鹿为马、垂帘听政、狸猫换太子 - sql outline》](../202105/20210525_01.md)  
  
## 高并发小事务  
1、配置较大的shared buffer.  
  
2、高并发, 就PG这种进程模型数据库, 我都吐槽过无数遍, 并发连接上千后性能急剧下降, 早晚得上内置连接池. 外置连接池增加了1跳, 而且外置连接池很难做到无缝迁移事务和会话变量, 限制较多. 第一优先推荐使用内置连接池, 参考:   
- 连接池/限制连接数 [《PostgresPro buildin pool(内置连接池)版本 原理与测试》](../201805/20180521_03.md)     
- 阿里云PolarDB shared server: https://apsaradb.github.io/PolarDB-for-PostgreSQL/zh/features/v11/performance/shared-server.html  
  
如果不能使用内置连接池, 一定要选一个好一点(支持多进程/多线程)的外置连接池.    
   
补充: 开启大页, 对连接数多、shared buffer大的场景能起到减少os层hashtable内存消耗的作用.   
  
3、拉长 checkpoint 周期, 可以配置:   
```  
#checkpoint_timeout = 1d             # range 30s-1d  
max_wal_size = 1GB  
min_wal_size = 64GB  
#checkpoint_flush_after =          # measured in pages, 0 disables  
```  
  
4、拉长 checkpoint_completion_target , 可以配置:  
```  
#checkpoint_completion_target = 0.9     # checkpoint target duration, 0.0 - 1.0  
```   
  
5、观察`pg_catalog.pg_stat_bgwriter`, 尽量减少buffers_backend_fsync, 调整bgwriter的工作量和间歇, 尽量让bgwriter去淘汰脏页, 可以配置:  
```  
#bgwriter_delay = 10ms                 # 10-10000ms between rounds  
#bgwriter_lru_maxpages = 500            # max buffers written/round, 0 disables  
#bgwriter_lru_multiplier = 2.0          # 0-10.0 multiplier on buffers scanned/round  
#bgwriter_flush_after = 512kB           # measured in pages, 0 disables  
```  
  
6、关闭hint和checksum, 降低CPU和datafile, wal日志量.   
```  
#wal_log_hints = off                    # also do full page writes of non-critical updates  
                                        # (change requires restart)  
```  
  
```  
initdb --help  
  -k, --data-checksums      use data page checksums  
```  
  
7、关闭计数器, pg_stat_statements等带来额外开销的插件.   
  
以上都属于君子配置, 没什么危害. 下面来一点作弊配置.    
  
1、少写点wal.    
```  
#wal_level = minimal                    # minimal  
```  
  
2、关闭 wal同步提交, 小事务写性能飙升.    
```  
synchronous_commit = off  
```  
  
数据库崩溃会丢数据, 但是不会导致数据不一致. 丢多少则取决于以下配置:    
```  
#wal_writer_delay = 200ms               # 1-10000 milliseconds  
#wal_writer_flush_after = 1MB           # measured in pages, 0 disables  
```  
  
3、关闭fpw, 以确保检查点期间性能丝滑. 如果你的文件系统是cow的, 大胆关闭fpw没有任何危害.   
```  
#full_page_writes = off  
```  
  
如果文件系统不是cow的, 关闭后可能导致坏块隐患. 参考阅读:   
- [《一起学PolarDB - 第2期 - 为什么FPW是以牺牲(性能、存储空间、稳定性)换取的可靠性?》](../202112/20211228_02.md)    
- [《DB吐槽大会,第11期 - FPW | Double Write》](../202108/20210830_02.md)    
  
4、关闭fsync, 高度危险参数, 相当于写IO全部异步了, 把压力给到OS刷脏. 带来的后果是数据库可能有丢数据、坏块等风险. 但是写性能会急剧提升.      
```  
#fsync = on                             # flush data to disk for crash safety  
                                        # (turning this off can cause  
                                        # unrecoverable data corruption)  
```  
  
## 批量导入  
1、使用最大的block size.  
  
2、使用unlogged table  
  
3、关闭全局或被导入表的autovacuum  
  
4、删除被导入表上不必要的索引  
  
5、批量导入, 例如使用copy导入、使用`insert into table values (),(),()...()`;   
  
6、使用pg_bulkload工具导入, 这个工具导入也是不写wal日志的.    
  
7、先把数据文件生成, 再导入. 这个解决的是block extent lock瓶颈.    
  
例如要导入1000万记录, 先导入进去, 然后删除除了最后一个数据块里的一条记录的其他所有记录, 然后vacuum这个表, 这样即使vacuum, 也不会回收物理空间, 而是把所有page都清空为可插入状态, 再次导入时就不需要分配block了.  
```
postgres=# create unlogged table tbl (id int, info text, ts timestamp) ;
CREATE TABLE
postgres=# \timing
Timing is on.
postgres=# insert into tbl select generate_series(1,10000000), md5(random()::text), now();
INSERT 0 10000000
Time: 5981.065 ms (00:05.981)

postgres=# select pg_size_pretty(pg_relation_size('tbl'));
 pg_size_pretty 
----------------
 730 MB
(1 row)

Time: 1.738 ms

-- 删除除最后一个数据块的某条记录以外的其他所有记录. 
postgres=# select relpages from pg_class where relname='tbl';
 relpages 
----------
    93458
(1 row)

Time: 8.636 ms

postgres=# select max(ctid) from tbl where ctid >= '(93457,0)' and ctid < '(93458,0)';
     max     
-------------
 (93457,101)
(1 row)

Time: 1.351 ms
postgres=# delete from tbl where ctid <> '(93457,101)';
DELETE 9999999
Time: 1290.774 ms (00:01.291)

postgres=# vacuum verbose tbl;
INFO:  vacuuming "public.tbl"
INFO:  table "tbl": removed 428 dead item identifiers in 4 pages
INFO:  table "tbl": found 428 removable, 1 nonremovable row versions in 8 out of 93458 pages
DETAIL:  0 dead row versions cannot be removed yet, oldest xmin: 737
Skipped 0 pages due to buffer pins, 93450 frozen pages.
CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s.
INFO:  vacuuming "pg_toast.pg_toast_16384"
INFO:  table "pg_toast_16384": found 0 removable, 0 nonremovable row versions in 0 out of 0 pages
DETAIL:  0 dead row versions cannot be removed yet, oldest xmin: 737
Skipped 0 pages due to buffer pins, 0 frozen pages.
CPU: user: 0.00 s, system: 0.00 s, elapsed: 0.00 s.
VACUUM
Time: 14.539 ms

postgres=# select pg_size_pretty(pg_relation_size('tbl'));
 pg_size_pretty 
----------------
 730 MB
(1 row)

Time: 0.658 ms

postgres=# insert into tbl select generate_series(1,10000000), md5(random()::text), now();
INSERT 0 10000000
Time: 5327.559 ms (00:05.328)
-- 此处如果是并发的多个会话写入, 性能提示会非常明显
```
  
8、使用高版本.   
  
目前extend lock冲突问题已得到一定的优化, 具体参考16版本的patch: [《PostgreSQL 16 preview - extend relation 优化, 扩展数据文件大幅度优化, 提升批量、高并发写入场景性能》](../202304/20230406_01.md)  

  
参考我的吐槽信息:  
- [《DB吐槽大会,第28期 - PG 每次只扩展1个block》](../202109/20210903_03.md)    
  
以上作弊手段, 学会了吗? 如果你PK赢了一定要来打赏一下哟.    
    
    
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
