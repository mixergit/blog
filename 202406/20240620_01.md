## PostgreSQL+pg_bestmatch+pgvector 打造适合自己文档库的TF-IDF加权, 库内将文本转换为向量, 提升文本搜索精确度和性能   
                       
### 作者                                              
digoal                                              
                                              
### 日期                                              
2024-06-20                                  
                                              
### 标签                             
PostgreSQL , PolarDB , DuckDB , tf-idf , 文本搜索 , bm25 , pg_bestmatch , vector , 向量 , 分词 , 结巴    
                                              
----                                              
                                              
## 背景    
  
[《PostgreSQL结合余弦、线性相关算法 在文本、图片、数组相似 等领域的应用 - 1 文本(关键词)分析理论基础 - TF(Term Frequency 词频)/IDF(Inverse Document Frequency 逆向文本频率)》](../201701/20170116_02.md)    
  
这篇文章详细介绍了如何使用PG的ts search功能和madlib插件, 通过海量本地文本计算出适合自己的tf、idf的方法.      
  
## TF-IDF算法      
TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。      
      
TF-IDF加权的各种形式常被搜索引擎应用，作为文件与用户查询之间相关程度的度量或评级。除了TF-IDF以外，因特网上的搜索引擎还会使用基于链接分析的评级方法，以确定文件在搜寻结果中出现的顺序。      
      
1\. tf比较好理解，就是一个词在当前文本的出现频率，后面会有例子。      
      
2\. idf是一个加权，逆向文件频率（inverse document frequency，IDF）是一个词语普遍重要性的度量。也就是说一些普通词，因此越普通的词，它的IDF越低。      
      
某一特定词语的IDF，可以由总文件数目除以包含该词语之文件的数目，再取对数得到IDF。      
      
3\. 计算一个词在文档中的关键性，计算TF与IDF的乘积即得到。因此，TF-IDF倾向于过滤掉常见的词语，保留重要的词语。      
      
### 例子    
      
有很多不同的数学公式可以用来计算TF-IDF。      
      
这边的例子以上述的数学公式来计算。      
      
1\. 词频 (TF) 是一词语出现的次数除以该文件的总词语数。      
      
假如一篇文件的总词语数是100个，而词语“母牛”出现了3次，那么“母牛”一词在该文件中的词频就是`3/100 = 0.03`。      
      
2\. 一个计算文件频率 (IDF) 的方法是文件集里包含的文件总数除以测定有多少份文件出现过“母牛”一词。      
      
所以，如果“母牛”一词在1,000份文件出现过，而文件总数是10,000,000份的话，其逆向文件频率就是 `log(10,000,000 / 1,000) = 4`。      
      
3\. 最后“母牛”的TF-IDF的分数为`0.03 * 4 = 0.12`。      
      
TF-IDF越高，说明这个词在该文本中越关键。   
  
提示: 中文文档的tf-idf统计, 可以结合结巴分词插件(pg_jieba)来.    
  
## pg_bestmatch  
pg_bestmatch 插件完成的功能与以上类似(统计tf-idf, 根据统计结果计算文本向量, 计算搜索语句向量, 结合pgvector通过向量相近的原理搜索语句与文本相似内容), 不过分词部分对中文的支持还不太好.    
  
pg_bestmatch插件现已集成到无敌镜像:   
- [《2023-PostgreSQL Docker镜像学习环境 ARM64版, 已集成热门插件和工具》](../202308/20230814_02.md)       
- [《2023-PostgreSQL Docker镜像学习环境 AMD64版, 已集成热门插件和工具》](../202307/20230710_03.md)      
  
  
以下是安装方法:  
```  
cd /tmp  
git clone --depth 1 https://github.com/tensorchord/pg_bestmatch.rs  
cd pg_bestmatch.rs  
cargo install cargo-pgrx --version 0.12.0-alpha.1  
cargo pgrx init --pg14=$(which pg_config)  
cargo pgrx install --release  
```  
  
创建插件  
```  
psql  
  
create extension vector;  
  
create extension pg_bestmatch;  
  
set search_path =bm_catalog ;  
```  
  
  
目前中文切词支持可能不是特别好, 体现在如下切词方面, tokenize如果能结合结巴分词, pg_bestmatch中文支持就更完美了:     
```  
postgres=# select * from tokenize('你好我是中国人, 目前就职于阿里巴巴, 花名德哥');  
                                             tokenize                                               
--------------------------------------------------------------------------------------------------  
 {[UNK],[UNK],我,[UNK],中,国,人,",",目,前,[UNK],[UNK],[UNK],阿,里,[UNK],[UNK],",",花,名,德,[UNK]}  
(1 row)  
  
SELECT tokenize('i have an apple'); -- result: {i,have,an,apple}  
```  
  
创建一张文本表, 写入几条文本.  
```  
create table tbl (id int, info text);  
  
postgres=# insert into tbl values (1, '你好,我是中国人,目前在杭州工作,网名德哥(digoal).');  
INSERT 0 1  
postgres=# insert into tbl values (1, 'hello, i am digoal, from hangzhou.');  
INSERT 0 1  
```  
  
生成这张表对应的tf-idf统计信息  
```  
postgres=# SELECT bm25_create('tbl','info','tbl_info');  
 bm25_create   
-------------  
   
(1 row)  
  
postgres=# select * from tbl_info ;  
 token  | id | how_many_tokens |    idf       
--------+----+-----------------+------------  
 ##l    |  0 |               2 | 0.18232156  
 ##oa   |  1 |               2 | 0.18232156  
 ##zhou |  2 |               1 |  0.6931472  
 (      |  3 |               1 |  0.6931472  
 )      |  4 |               1 |  0.6931472  
 ,      |  5 |               5 | 0.18232156  
 .      |  6 |               2 | 0.18232156  
 [UNK]  |  7 |               9 |  0.6931472  
 am     |  8 |               1 |  0.6931472  
 dig    |  9 |               2 | 0.18232156  
 from   | 10 |               1 |  0.6931472  
 hang   | 11 |               1 |  0.6931472  
 hello  | 12 |               1 |  0.6931472  
 i      | 13 |               1 |  0.6931472  
 中     | 14 |               1 |  0.6931472  
 人     | 15 |               1 |  0.6931472  
 前     | 16 |               1 |  0.6931472  
 名     | 17 |               1 |  0.6931472  
 国     | 18 |               1 |  0.6931472  
 州     | 19 |               1 |  0.6931472  
 德     | 20 |               1 |  0.6931472  
 我     | 21 |               1 |  0.6931472  
 目     | 22 |               1 |  0.6931472  
(23 rows)  
```  
  
根据这张表的统计信息, 计算每一条文本的向量值  
```  
postgres=# SELECT bm25_document_to_svector('tbl_info','我是中国人','pgvector');  
                         bm25_document_to_svector                           
--------------------------------------------------------------------------  
 {8:0.6532663, 15:0.6532663, 16:0.6532663, 19:0.6532663, 22:0.6532663}/23  
(1 row)  
```  
  
  
根据这张表的统计信息, 计算查询语句的向量值  
```  
postgres=# SELECT bm25_query_to_svector('tbl_info','谁是德哥','pgvector')::sparsevec;  
 bm25_query_to_svector   
-----------------------  
 {8:0.5,21:0.5}/23  
(1 row)  
```  
  
给文本表添加一个向量字段, 更新该字段值  
```  
alter table tbl add column vec sparsevec;  
  
update tbl set vec=bm25_document_to_svector('tbl_info',info,'pgvector')::sparsevec;  
```  
  
以后搜索就可以使用向量相似的方法进行搜索, 例如使用'谁是德哥'进行搜索.   
```  
select vec <#> '{8:0.5,21:0.5}/23',* from tbl order by vec <#> '{8:0.5,21:0.5}/23';  
```  
  
```  
-[ RECORD 1 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
?column? | -0.6230704188346863  
id       | 1  
info     | 你好,我是中国人,目前在杭州工作,网名德哥(digoal).  
vec      | {1:0.39274922,2:0.39274922,4:0.39274922,5:0.39274922,6:0.65989846,7:0.39274922,8:0.85339165,10:0.39274922,15:0.39274922,16:0.39274922,17:0.39274922,18:0.39274922,19:0.39274922,20:0.39274922,21:0.39274922,22:0.39274922,23:0.39274922}/23  
-[ RECORD 2 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
?column? | -0  
id       | 1  
info     | hello, i am digoal, from hangzhou.  
vec      | {1:0.53941905,2:0.53941905,3:0.53941905,6:0.7008086,7:0.53941905,9:0.53941905,10:0.53941905,11:0.53941905,12:0.53941905,13:0.53941905,14:0.53941905}/23  
```  
  
更多搜索例子  
```  
postgres=# SELECT bm25_query_to_svector('tbl_info','where are digoal from?','pgvector')::sparsevec;  
-[ RECORD 1 ]---------+----------------------------------------------------------  
bm25_query_to_svector | {1:0.14702027,2:0.14702027,10:0.14702027,11:0.5589393}/23  
  
postgres=# select vec <#> '{1:0.14702027,2:0.14702027,10:0.14702027,11:0.5589393}/23',* from tbl order by vec <#> '{1:0.14702027,2:0.14702027,10:0.14702027,11:0.5589393}/23';  
-[ RECORD 1 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
?column? | -0.5394191145896912  
id       | 1  
info     | hello, i am digoal, from hangzhou.  
vec      | {1:0.53941905,2:0.53941905,3:0.53941905,6:0.7008086,7:0.53941905,9:0.53941905,10:0.53941905,11:0.53941905,12:0.53941905,13:0.53941905,14:0.53941905}/23  
-[ RECORD 2 ]-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  
?column? | -0.1732262820005417  
id       | 1  
info     | 你好,我是中国人,目前在杭州工作,网名德哥(digoal).  
vec      | {1:0.39274922,2:0.39274922,4:0.39274922,5:0.39274922,6:0.65989846,7:0.39274922,8:0.85339165,10:0.39274922,15:0.39274922,16:0.39274922,17:0.39274922,18:0.39274922,19:0.39274922,20:0.39274922,21:0.39274922,22:0.39274922,23:0.39274922}/23  
```  
  
## 参考  
https://blog.pgvecto.rs/pgbestmatchrs-elevate-your-postgresql-text-queries-with-bm25  
  
[《PostgreSQL结合余弦、线性相关算法 在文本、图片、数组相似 等领域的应用 - 3 rum, smlar应用场景分析》](../201701/20170116_04.md)    
  
[《PostgreSQL结合余弦、线性相关算法 在文本、图片、数组相似 等领域的应用 - 2 smlar插件详解》](../201701/20170116_03.md)    
  
[《PostgreSQL结合余弦、线性相关算法 在文本、图片、数组相似 等领域的应用 - 1 文本(关键词)分析理论基础 - TF(Term Frequency 词频)/IDF(Inverse Document Frequency 逆向文本频率)》](../201701/20170116_02.md)    
  
https://github.com/tensorchord/pg_bestmatch.rs  
  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
