## 性能爽翻了, 在PolarDB plpython中使用DuckDB    
                                                                                   
### 作者                                                                        
digoal                                                                          
                                                                                          
### 日期                                                                                        
2024-11-25                                                      
                                                 
### 标签                                                                      
PostgreSQL , PolarDB , DuckDB , plpython , 性能 , 代理函数 , 优化器 , query rewrite , postgres_scanner , csv_reader , parquet_reader        
                                                                                                              
----                                                                                       
                                                                                                     
## 背景   
为什么要在PolarDB PostgreSQL中使用duckdb? 还不是因为PG 在复杂分析查询方面优化器做得太慢了, 弱爆了. 已经写过很多对比文章, 不再细说.       
  
[《PG被DuckDB碾压,该反省哪些方面? DuckDB v0.10.3 在Macmini 2023款上的tpch性能表现如何? PostgreSQL使用duckdb_fdw 的tpch加速性能表现如何?》](../202405/20240525_01.md)    
  
为什么现在要来说这个? PolarDB/PostgreSQL不是早就支持plpython存储过程了么, 还不是因为要打比赛, 给直接来个上次问AI得到的核爆级弯道超车思路.      
  
[《qwen2.5-coder真牛~~用它打PolarDB国赛劲劲的》](../202411/20241115_01.md)    
  
AI给了思路和DEMO代码, 我就试试到底行不行, 有多少提升? 结果嘛不用说, 不同的SQL提升各不相同, 拿Q17来说, 可能提升上百倍性能.    
   
为什么不用更简单的pg_duckdb, duckdb_fdw, pg_analytic插件呢? 因为比赛分支是基于PostgreSQL 11的, 这个版本还没有TAM接口, 所以无法支持pg_duckdb和pg_analytic插件, 而duckdb_fdw是被禁止的.    
   
## DEMO  
我假设你已经按下面的指南部署好了环境, 在容器内操作.  
- [《PolarDB数据库创新设计国赛 - 初赛提交作品指南》](../202410/20241008_04.md)    
  
首先需要把一些依赖包放到你的代码包里, 后面你需要把安装过程写入build.sh脚本内     
  
https://pypi.org/project/setuptools/  
  
```  
cd /tmp  
curl https://files.pythonhosted.org/packages/11/0a/7f13ef5cd932a107cd4c0f3ebc9d831d9b78e1a0e8c98a098ca17b1d7d97/setuptools-41.6.0.zip -o ./setuptools-41.6.0.zip  
  
sudo apt-get install -y unzip  
unzip setuptools-41.6.0.zip   
tar -zcvf setuptools-41.6.0.tar.gz setuptools-41.6.0  
cd setuptools-41.6.0  
sudo python3 setup.py install  
```  
  
https://pypi.org/project/pip/  
  
```  
cd /tmp  
curl https://files.pythonhosted.org/packages/ce/ea/9b445176a65ae4ba22dce1d93e4b5fe182f953df71a145f557cffaffc1bf/pip-19.3.1.tar.gz -o ./pip-19.3.1.tar.gz  
  
tar -zxvf pip-19.3.1.tar.gz   
cd pip-19.3.1  
sudo python3 setup.py install  
```  
  
https://pypi.org/project/duckdb/   
  
duckdb包请根据你的开发环境选择, 我用的是m2 芯片mac, 下载arm版本. 测试机可能是x86, 得选另一个.  
```
# cd /tmp
# curl https://files.pythonhosted.org/packages/e9/35/3fa9b1bbbf4e91e680abfb4c2a2560802698b43c6720096aae0c2d6ef7eb/duckdb-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl -o ./duckdb-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl  
# sudo pip3.8 install ./duckdb-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl 

  
cd /tmp  
curl https://files.pythonhosted.org/packages/37/7c/cf0a0dd56e84570b94927a522698c49fd173b38074ab41a9eb044127b3b3/duckdb-1.1.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl -o ./duckdb-1.1.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl  
  
sudo pip3.8 install ./duckdb-1.1.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl  
```  
  
  
现在你可以创建一个plpython3u函数, 在里面可以import duckdb了.  
```  
postgres=# create extension plpython3u ;  
  
-- 创建或替换函数    
CREATE OR REPLACE FUNCTION duckdb_proxy(query_text TEXT) RETURNS SETOF RECORD AS $$    
import duckdb    
    
# 连接到 DuckDB 数据库    
con = duckdb.connect(database=':memory:')    
    
# 执行查询    
result = con.execute(query_text)    
    
# 获取结果并返回    
for row in result.fetchall():    
    yield tuple(row)    
    
# 关闭连接    
con.close()    
$$ LANGUAGE plpython3u;    
```  
  
  
  
下面在python shell中把data目录中的csv文件都转换成parquet文件, 可以大幅提升性能. 类型请参考dss.sql文件进行定义.       
```  
$ python3.8   
  
import duckdb   
  
duckdb.sql("""copy (select * from   
  read_csv('/data/customer.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'c_custkey': 'INTEGER',  
      'c_name': 'VARCHAR(25)',  
      'c_address': 'VARCHAR(40)',  
      'c_nationkey': 'INTEGER',  
      'c_phone': 'CHAR(15)',  
      'c_acctbal': 'DECIMAL(15,2)',  
      'c_mktsegment': 'CHAR(10)',  
      'c_comment': 'VARCHAR(117)'  
    }  
  )  
) to '/data/customer.parquet'""")  
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/nation.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'n_nationkey': 'INTEGER',  
      'n_name': 'CHAR(25)',  
      'n_regionkey': 'INTEGER',  
      'n_comment': 'VARCHAR(152)'  
    }  
  )  
) to '/data/nation.parquet'""")   
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/lineitem.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'l_orderkey': 'INTEGER',  
      'l_partkey': 'INTEGER',  
      'l_suppkey': 'INTEGER',  
      'l_linenumber': 'INTEGER',  
      'l_quantity': 'DECIMAL(15,2)',  
      'l_extendedprice': 'DECIMAL(15,2)',  
      'l_discount': 'DECIMAL(15,2)',  
      'l_tax': 'DECIMAL(15,2)',  
      'l_returnflag': 'CHAR(1)',  
      'l_linestatus': 'CHAR(1)',  
      'l_shipdate': 'DATE',  
      'l_commitdate': 'DATE',  
      'l_receiptdate': 'DATE',  
      'l_shipinstruct': 'CHAR(25)',  
      'l_shipmode': 'CHAR(10)',  
      'l_comment': 'VARCHAR(44)'  
    }  
  )  
) to '/data/lineitem.parquet'""")   
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/orders.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'o_orderkey': 'INTEGER',  
      'o_custkey': 'INTEGER',  
      'o_orderstatus': 'CHAR(1)',  
      'o_totalprice': 'DECIMAL(15,2)',  
      'o_orderdate': 'DATE',  
      'o_orderpriority': 'CHAR(15)',  
      'o_clerk': 'CHAR(15)',  
      'o_shippriority': 'INTEGER',  
      'o_comment': 'VARCHAR(79)'  
    }  
  )  
) to '/data/orders.parquet'""")   
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/part.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'p_partkey': 'INTEGER',  
      'p_name': 'VARCHAR(55)',  
      'p_mfgr': 'CHAR(25)',  
      'p_brand': 'CHAR(10)',  
      'p_type': 'VARCHAR(25)',  
      'p_size': 'INTEGER',  
      'p_container': 'CHAR(10)',  
      'p_retailprice': 'DECIMAL(15,2)',  
      'p_comment': 'VARCHAR(23)'  
    }  
  )  
) to '/data/part.parquet'""")   
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/partsupp.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'ps_partkey': 'INTEGER',  
      'ps_suppkey': 'INTEGER',  
      'ps_availqty': 'INTEGER',  
      'ps_supplycost': 'DECIMAL(15,2)',  
      'ps_comment': 'VARCHAR(199)'  
    }  
  )  
) to '/data/partsupp.parquet'""")   
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/region.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      'r_regionkey': 'INTEGER',  
      'r_name': 'CHAR(25)',  
      'r_comment': 'VARCHAR(152)'  
    }  
  )  
) to '/data/region.parquet'""")   
  
  
duckdb.sql("""copy (select * from   
  read_csv('/data/supplier.tbl',  
    delim = '|',  
    header = false,  
    columns = {  
      's_suppkey': 'INTEGER',  
      's_name': 'CHAR(55)',  
      's_address': 'VARCHAR(40)',  
      's_nationkey': 'INTEGER',  
      's_phone': 'CHAR(15)',  
      's_acctbal': 'DECIMAL(15,2)',  
      's_comment': 'VARCHAR(101)'  
    }  
  )  
) to '/data/supplier.parquet'""")   
```  
  
抽查一下转换后的parquet文件数据是否正常  
```  
>>> duckdb.sql("select * from read_parquet('/data/customer.parquet') limit 10")  
┌───────────┬────────────────────┬──────────────────────┬─────────────┬─────────────────┬───────────────┬──────────────┬─────────────────────────────────────────────────────────────────────────────────┐  
│ c_custkey │       c_name       │      c_address       │ c_nationkey │     c_phone     │   c_acctbal   │ c_mktsegment │                                    c_comment                                    │  
│   int32   │      varchar       │       varchar        │    int32    │     varchar     │ decimal(15,2) │   varchar    │                                     varchar                                     │  
├───────────┼────────────────────┼──────────────────────┼─────────────┼─────────────────┼───────────────┼──────────────┼─────────────────────────────────────────────────────────────────────────────────┤  
│         1 │ Customer#000000001 │ IVhzIApeRb ot,c,E    │          15 │ 25-989-741-2988 │        711.56 │ BUILDING     │ to the even, regular platelets. regular, ironic epitaphs nag e                  │  
│         2 │ Customer#000000002 │ XSTf4,NCwDVaWNe6tE…  │          13 │ 23-768-687-3665 │        121.65 │ AUTOMOBILE   │ l accounts. blithely ironic theodolites integrate boldly: caref                 │  
│         3 │ Customer#000000003 │ MG9kdTD2WBHm         │           1 │ 11-719-748-3364 │       7498.12 │ AUTOMOBILE   │  deposits eat slyly ironic, even instructions. express foxes detect slyly. bl…  │  
│         4 │ Customer#000000004 │ XxVSJsLAGtn          │           4 │ 14-128-190-5944 │       2866.83 │ MACHINERY    │  requests. final, regular ideas sleep final accou                               │  
│         5 │ Customer#000000005 │ KvpyuHCplrB84WgAiG…  │           3 │ 13-750-942-6364 │        794.47 │ HOUSEHOLD    │ n accounts will have to unwind. foxes cajole accor                              │  
│         6 │ Customer#000000006 │ sKZz0CsnMD7mp4Xd0Y…  │          20 │ 30-114-968-4951 │       7638.57 │ AUTOMOBILE   │ tions. even deposits boost according to the slyly bold packages. final accoun…  │  
│         7 │ Customer#000000007 │ TcGe5gaZNgVePxU5kR…  │          18 │ 28-190-982-9759 │       9561.95 │ AUTOMOBILE   │ ainst the ironic, express theodolites. express, even pinto beans among the exp  │  
│         8 │ Customer#000000008 │ I0B10bB0AymmC, 0Pr…  │          17 │ 27-147-574-9335 │       6819.74 │ BUILDING     │ among the slyly regular theodolites kindle blithely courts. carefully even th…  │  
│         9 │ Customer#000000009 │ xKiAFTjUsCuxfeleNq…  │           8 │ 18-338-906-3675 │       8324.07 │ FURNITURE    │ r theodolites according to the requests wake thinly excuses: pending requests…  │  
│        10 │ Customer#000000010 │ 6LrEaV6KR6PLVcgl2A…  │           5 │ 15-741-346-9870 │       2753.54 │ HOUSEHOLD    │ es regular deposits haggle. fur                                                 │  
├───────────┴────────────────────┴──────────────────────┴─────────────┴─────────────────┴───────────────┴──────────────┴─────────────────────────────────────────────────────────────────────────────────┤  
│ 10 rows                                                                                                                                                                                      8 columns │  
└────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘  
  
  
>>> duckdb.sql("select count(*) from read_parquet('/data/customer.parquet')")    
┌──────────────┐  
│ count_star() │  
│    int64     │  
├──────────────┤  
│        15000 │  
└──────────────┘  
```  
  
### 1、parquet reader  
为了在PostgreSQL中调用方便, 可以把这8个parquet文件创建为对应的视图, 并把视图保留到duckdb数据文件`/data/duckdb_proxy.db`中  
```  
con = duckdb.connect(database='/data/duckdb_proxy.db')    
  
con.execute("""  
CREATE or replace view customer as select * from '/data/customer.parquet';  
CREATE or replace view lineitem as select * from '/data/lineitem.parquet';  
CREATE or replace view nation as select * from '/data/nation.parquet';  
CREATE or replace view orders as select * from '/data/orders.parquet';  
CREATE or replace view part as select * from '/data/part.parquet';  
CREATE or replace view partsupp as select * from '/data/partsupp.parquet';  
CREATE or replace view region as select * from '/data/region.parquet';  
CREATE or replace view supplier as select * from '/data/supplier.parquet';  
""")    
  
con.checkpoint()  
```  
  
现在可以直接查询这些视图, 相当于查的后面的parquet文件.  
```  
con.sql('select count(*) from customer')  
con.sql('select count(*) from lineitem')  
con.sql('select count(*) from nation')  
con.sql('select count(*) from orders')  
con.sql('select count(*) from part')  
con.sql('select count(*) from partsupp')  
con.sql('select count(*) from region')  
con.sql('select count(*) from supplier')  
```  
  
找个tpch query来试一下, 性能杠杠的  
```  
con.sql("""  
select  
	l_returnflag,  
	l_linestatus,  
	sum(l_quantity) as sum_qty,  
	sum(l_extendedprice) as sum_base_price,  
	sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,  
	sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,  
	avg(l_quantity) as avg_qty,  
	avg(l_extendedprice) as avg_price,  
	avg(l_discount) as avg_disc,  
	count(*) as count_order  
from  
	lineitem  
where  
	l_shipdate <= date '1998-12-01' - interval '100' day  
group by  
	l_returnflag,  
	l_linestatus  
order by  
	l_returnflag,  
	l_linestatus;""")  
  
  
  
┌──────────────┬──────────────┬───────────────┬────────────────┬─────────────────┬────────────────────┬────────────────────┬────────────────────┬─────────────────────┬─────────────┐  
│ l_returnflag │ l_linestatus │    sum_qty    │ sum_base_price │ sum_disc_price  │     sum_charge     │      avg_qty       │     avg_price      │      avg_disc       │ count_order │  
│   varchar    │   varchar    │ decimal(38,2) │ decimal(38,2)  │  decimal(38,4)  │   decimal(38,6)    │       double       │       double       │       double        │    int64    │  
├──────────────┼──────────────┼───────────────┼────────────────┼─────────────────┼────────────────────┼────────────────────┼────────────────────┼─────────────────────┼─────────────┤  
│ A            │ F            │    3774200.00 │  5320753880.69 │ 5054096266.6828 │  5256751331.449234 │ 25.537587116854997 │  36002.12382901414 │ 0.05014459706340077 │      147790 │  
│ N            │ F            │      95257.00 │   133737795.84 │  127132372.6512 │   132286291.229445 │  25.30066401062417 │  35521.32691633466 │ 0.04939442231075697 │        3765 │  
│ N            │ O            │    7407220.00 │ 10438352681.32 │ 9916049778.5866 │ 10312596801.845673 │ 25.545573370211855 │  35999.16085721873 │ 0.05009328840775139 │      289961 │  
│ R            │ F            │    3785523.00 │  5337950526.47 │ 5071818532.9420 │  5274405503.049367 │   25.5259438574251 │ 35994.029214030925 │ 0.04998927856184382 │      148301 │  
└──────────────┴──────────────┴───────────────┴────────────────┴─────────────────┴────────────────────┴────────────────────┴────────────────────┴─────────────────────┴─────────────┘  
```  
  
关闭连接  
```  
con.close()  
```  
  
更多的duckdb python api请查看手册  
- https://duckdb.org/docs/api/python/reference/    
  
接下来可以用PostgreSQL函数, 把SQL请求转发给duckdb执行了, 还是用到这个函数, 返回setof record, 这样比较通用, 一个函数就可以转发所有tpch query.  
```  
-- 创建或替换函数    
CREATE OR REPLACE FUNCTION duckdb_proxy(query_text TEXT) RETURNS SETOF RECORD AS $$    
import duckdb    
    
# 连接到 DuckDB 数据库    
con = duckdb.connect(database='/data/duckdb_proxy.db')    
    
# 获取结果并返回    
for row in tuple(con.execute(query_text).fetchall()):    
    yield row  
    
# 关闭连接    
con.close()    
$$ LANGUAGE plpython3u;    
```  
  
用下面的SQL试试这个函数好不好用?  
```  
select * from duckdb_proxy($$select count(*) from customer$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from lineitem$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from nation$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from orders$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from part$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from partsupp$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from region$$) as t(c int8);  
select * from duckdb_proxy($$select count(*) from supplier$$) as t(c int8);  
```  
  
可以了  
```  
postgres=# select * from duckdb_proxy($$select count(*) from customer$$) as t(c int8);  
   c     
-------  
 15000  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from lineitem$$) as t(c int8);  
   c      
--------  
 600572  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from nation$$) as t(c int8);  
 c    
----  
 25  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from orders$$) as t(c int8);  
   c      
--------  
 150000  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from part$$) as t(c int8);  
   c     
-------  
 20000  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from partsupp$$) as t(c int8);  
   c     
-------  
 80000  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from region$$) as t(c int8);  
 c   
---  
 5  
(1 row)  
  
postgres=# select * from duckdb_proxy($$select count(*) from supplier$$) as t(c int8);  
  c     
------  
 1000  
(1 row)  
```  
  
接下来你可能要问, 每次都要定义result table的结构, 字段名可以随便取, 但是我怎么知道返回的每个字段是什么类型呢?  两种方法:  
  
1, 使用duckdb跑一遍, 看看duckdb返回了什么类型,   
```  
con.sql("""  
select  
	l_returnflag,  
	l_linestatus,  
	sum(l_quantity) as sum_qty,  
	sum(l_extendedprice) as sum_base_price,  
	sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,  
	sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,  
	avg(l_quantity) as avg_qty,  
	avg(l_extendedprice) as avg_price,  
	avg(l_discount) as avg_disc,  
	count(*) as count_order  
from  
	lineitem  
where  
    l_shipdate <= ( date '1998-12-01' - interval '100' day )  
group by  
	l_returnflag,  
	l_linestatus  
order by  
	l_returnflag,  
	l_linestatus  
""")  
```  
  
例如第一条前面已经跑了, 从结果中照抄, 但是一定要注意, 不要随便用float8, 除非在PG中本来也是返回float8, 否则建议改成decimal, 保证精度  
```  
select * from duckdb_proxy($$  
select  
	l_returnflag,  
	l_linestatus,  
	sum(l_quantity) as sum_qty,  
	sum(l_extendedprice) as sum_base_price,  
	sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,  
	sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,  
	avg(l_quantity) as avg_qty,  
	avg(l_extendedprice) as avg_price,  
	avg(l_discount) as avg_disc,  
	count(*) as count_order  
from  
	lineitem  
where  
    l_shipdate <= ( date '1998-12-01' - interval '100' day )  
group by  
	l_returnflag,  
	l_linestatus  
order by  
	l_returnflag,  
	l_linestatus  
$$) as t (  
l_returnflag varchar,  
l_linestatus varchar,  
sum_qty decimal(38,2),  
sum_base_price decimal(38,2),  
sum_disc_price decimal(38,4),  
sum_charge decimal(38,6),  
avg_qty decimal,  -- 不要使用float8, 结果可能不正确  
avg_price decimal,  -- 不要使用float8, 结果可能不正确  
avg_disc decimal,  -- 不要使用float8, 结果可能不正确  
count_order int8  
);    
```  
  
2, 方法2是使用pg_typeof函数, 可以知道返回的是什么类型, 但是要使用PG本地表跑一遍, 例如  
```  
postgres=# select  
pg_typeof(sum(l_extendedprice) / 7.0) as avg_yearly   
from  
lineitem,  
part  
where  
    p_partkey = l_partkey  
and p_brand = 'Brand#13'  
and p_container = 'JUMBO PKG'  
and l_quantity < (  
select  
0.2 * avg(l_quantity)  
from  
lineitem  
where  
            l_partkey = p_partkey  
);  
 avg_yearly   
------------  
 numeric  
(1 row)  
```  
  
  
tpch 的q17在PG里面跑是比较慢的对吧?   
```  
select  
	sum(l_extendedprice) / 7.0 as avg_yearly  
from  
	lineitem,  
	part  
where  
    p_partkey = l_partkey  
	and p_brand = 'Brand#13'  
	and p_container = 'JUMBO PKG'  
	and l_quantity < (  
		select  
			0.2 * avg(l_quantity)  
		from  
			lineitem  
		where  
            l_partkey = p_partkey  
	);  
  
     avg_yearly       
--------------------  
 28135.621428571429  -- 小数点12位  
(1 row)  
  
Time: 11898.286 ms (00:11.898)  
```  
  
在duckdb中小意思     
```  
con.sql("""  
select  
	sum(l_extendedprice) / 7.0 as avg_yearly  
from  
	lineitem,  
	part  
where  
    p_partkey = l_partkey  
	and p_brand = 'Brand#13'  
	and p_container = 'JUMBO PKG'  
	and l_quantity < (  
		select  
			0.2 * avg(l_quantity)  
		from  
			lineitem  
		where  
            l_partkey = p_partkey  
	);  
""")  
  
  
┌───────────────────┐  
│    avg_yearly     │  
│      double       │  
├───────────────────┤  
│ 28135.62142857143 │  -- 小数点11位  
└───────────────────┘  
```  
  
注意上面这个精度问题, 实际是是PG返回的numeric, 而duckdb返回的是float8.     
  
PG有个相关参数extra_float_digits, 可以控制浮点精度, 但是duckdb貌似没有, 可能需要改duckdb代码?  -- 这里就不细说了.    
  
q17 改写成代理SQL如下, 性能直接提升200多倍.    
```  
select * from duckdb_proxy($$  
select  
	sum(l_extendedprice) / 7.0 as avg_yearly  
from  
	lineitem,  
	part  
where  
    p_partkey = l_partkey  
	and p_brand = 'Brand#13'  
	and p_container = 'JUMBO PKG'  
	and l_quantity < (  
		select  
			0.2 * avg(l_quantity)  
		from  
			lineitem  
		where  
            l_partkey = p_partkey  
	)  
$$) as t (  
avg_yearly decimal    -- 不要使用float8, 结果可能不正确       
);    
  
    avg_yearly       
-------------------  
 28135.62142857143  -- 因为duckdb使用了float8, 所以结果并没有fix     
(1 row)  
  
Time: 56.766 ms  
```
    
你需要测试tpch的其他SQL的话, 可以使用qgen生成, 方法如下:  
```
cd /tmp/PolarDB-for-PostgreSQL/tpch-dbgen
cp qgen dists.dss queries/
cd queries/

./qgen -h
TPC-H Parameter Substitution (v. 2.14.0 build 0)
Copyright Transaction Processing Performance Council 1994 - 2010
USAGE: ./qgen <options> [ queries ]
Options:
	-a		-- use ANSI semantics.
	-b <str>	-- load distributions from <str>
	-c		-- retain comments found in template.
	-d		-- use default substitution values.
	-h		-- print this usage summary.
	-i <str>	-- use the contents of file <str> to begin a query.
	-l <str>	-- log parameters to <str>.
	-n <str>	-- connect to database <str>.
	-N		-- use default rowcounts and ignore :n directive.
	-o <str>	-- set the output file base path to <str>.
	-p <n>		-- use the query permutation for stream <n>
	-r <n>		-- seed the random number generator with <n>
	-s <n>		-- base substitutions on an SF of <n>
	-v		-- verbose.
	-t <str>	-- use the contents of file <str> to complete a query
	-x		-- enable SET EXPLAIN in each query.

# 例如 生成q1,q17,q18,q20,q21 . -s 0.1 不需要也可以. 因为我前面使用了scale 0.1生成数据.  
./qgen -s 0.1 -d 1 
./qgen -s 0.1 -d 17 
./qgen -s 0.1 -d 18 
./qgen -s 0.1 -d 20 
./qgen -s 0.1 -d 21 
```
  
### 2、postgres_scanner    
postgres_scanner, 把DuckDB当成PG的计算引擎.  
  
下面的测试环境m2模拟x86容器, TPCH SF=5.     
    
如果使用postgres_scanner, 就可以把DuckDB完全当成一个计算引擎来使用, 只要把PG里的表映射一份结构到DuckDB即可. 在进行DEMO之前, 先回答几个问题:      
- 会不会下推条件? 会, 有参数`pg_experimental_filter_pushdown`控制, 见 https://duckdb.org/docs/extensions/postgres.html     
    - `con.sql('SET pg_experimental_filter_pushdown=true')`    
- 会不会下推字段? 会, 只查询需要的字段     
- 会不会并行获取? 会, 按ctid分段并行获取, 通过参数`pg_pages_per_task` `pg_use_ctid_scan`控制, 见 [《duckdb postgres_scan 插件 - 不落地数据, 加速PostgreSQL数据分析》](../202210/20221001_02.md)      
    - `con.sql('SET pg_use_ctid_scan=true')` , `con.sql('SET pg_pages_per_task=1000')`      
    - 备注: duckdb cli观察到了并行, 但是在python duckdb API里没有看到并行.     
- 会不会内存溢出? 我想应该不会, 因为可以处理大于内存的数据, 没有验证. 见 [《DuckDB高效内存管理: 流式执行 , 临时文件 , 缓冲区管理》](../202407/20240717_01.md)      
       
#### DEMO    
1、首先配置一下PolarDB PostgreSQL的日志审计, 便于观察DuckDB发起了哪些请求到PG里面    
```    
postgres=# alter system set log_statement='all';    
    
postgres=# select pg_reload_conf();    
 pg_reload_conf     
----------------    
 t    
(1 row)    
```    
    
在pg_log的audit中可以观察日志    
```    
postgres@3847ee12e901:~/tmp_master_dir_polardb_pg_1100_bld/pg_log$ pwd    
/home/postgres/tmp_master_dir_polardb_pg_1100_bld/pg_log    
    
less postgresql-2024-11-27_111939_0_audit.log    
    
2024-11-27 13:55:31.031 CST [45041] [45041] LOG:  statement: BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ    
2024-11-27 13:55:31.031 CST [45041] [45041] LOG:  statement:     
        COPY (SELECT "l_shipdate" FROM "public"."lineitem" WHERE ("l_shipdate" <= '1998-08-23' AND "l_shipdate" IS NOT NULL)) TO STDOUT (FORMAT "binary");    
            
2024-11-27 13:55:31.031 CST [45041] [45041] LOG:  statement: COMMIT    
```    
    
2、安装DuckDB postgres_scanner插件    
```    
postgres@3847ee12e901:~$ python3.8    
Python 3.8.10 (default, Jul 29 2024, 17:02:10)     
[GCC 9.4.0] on linux    
Type "help", "copyright", "credits" or "license" for more information.    
>>> import duckdb    
con>>> con = duckdb.connect('/data/duckdb_proxy.db')    
>>> con.install_extension('postgres_scanner')    
100% ▕████████████████████████████████████████████████████████████▏     
>>> con.load_extension('postgres_scanner')    
>>>     
```    
    
如果在比赛评测机上无法联网, 可以把下好的插件拷贝到对应位置即可    
```    
postgres@3847ee12e901:~/.duckdb/extensions/v1.1.3/linux_amd64_gcc4$ pwd    
/home/postgres/.duckdb/extensions/v1.1.3/linux_amd64_gcc4    
    
postgres@3847ee12e901:~/.duckdb/extensions/v1.1.3/linux_amd64_gcc4$ ll    
total 46904    
drwxr-xr-x 2 postgres postgres     4096 Nov 27 11:30 ./    
drwxr-xr-x 3 postgres postgres     4096 Nov 27 11:30 ../    
-rw-r--r-- 1 postgres postgres 48013534 Nov 27 11:30 postgres_scanner.duckdb_extension    
-rw-r--r-- 1 postgres postgres      175 Nov 27 11:30 postgres_scanner.duckdb_extension.info    
```    
    
3、创建视图, 映射到PolarDB PostgreSQL中    
```    
>>> con.sql("""ATTACH 'dbname=postgres user=postgres host=/home/postgres/tmp_master_dir_polardb_pg_1100_bld port=5432' AS polardb (TYPE POSTGRES, SCHEMA 'public')""")    
>>> con.sql("""create or replace view customer as select * from polardb.customer""")    
>>> con.sql("""create or replace view lineitem as select * from polardb.lineitem""")    
>>> con.sql("""create or replace view nation as select * from polardb.nation""")    
>>> con.sql("""create or replace view orders as select * from polardb.orders""")    
>>> con.sql("""create or replace view part as select * from polardb.part""")    
>>> con.sql("""create or replace view partsupp as select * from polardb.partsupp""")    
>>> con.sql("""create or replace view region as select * from polardb.region""")    
>>> con.sql("""create or replace view supplier as select * from polardb.supplier""")    
>>> con.sql('select count(*) from lineitem')    
┌──────────────┐    
│ count_star() │    
│    int64     │    
├──────────────┤    
│       600572 │    
└──────────────┘    
>>> con.checkpoint()    
>>> con.close()    
```    
    
4、在PolarDB PostgreSQL中创建代理函数, `PolarDB PostgreSQL -> Compute by DuckDB -> fetch from PolarDB PostgreSQL`    
```    
-- 创建或替换函数        
CREATE OR REPLACE FUNCTION duckdb_proxy(    
  query_text TEXT,     
  IN idbname text default 'postgres',    
  IN iuser text default 'postgres',    
  IN ihost text default '/home/postgres/tmp_master_dir_polardb_pg_1100_bld',    
  IN iport text default '5432',     
  IN ischema text default 'public'     
)     
RETURNS SETOF RECORD AS $$        
import duckdb        
        
# 连接到 DuckDB 数据库        
con = duckdb.connect(database='/data/duckdb_proxy.db')        
    
# 连接 PolarDB PostgreSQL 数据库, 并设置postgres_scanner参数.      
con.sql("ATTACH 'dbname=" + idbname + " user=" + iuser + " host=" + ihost + " port=" + iport + "' AS polardb (TYPE POSTGRES, SCHEMA '" + ischema + "')")    
con.sql('SET pg_experimental_filter_pushdown=true')    
con.sql('SET pg_use_ctid_scan=true')    
con.sql('SET pg_pages_per_task=1000')     
con.sql('SET threads = 4')     
con.sql("SET memory_limit = '4GB'")     
        
# 获取结果并返回        
for row in tuple(con.execute(query_text).fetchall()):        
    yield row      
        
# 关闭连接        
con.close()        
$$ LANGUAGE plpython3u;      
```    
    
查看DuckDB执行计划    
```    
postgres=# select p from duckdb_proxy($$    
explain select count(*) from lineitem where    
  l_shipdate <= ( date '1998-12-01' - interval '100' day )     
$$) as t (x text, p text);     
    
               p                   
-------------------------------    
 ┌───────────────────────────┐+    
 │    UNGROUPED_AGGREGATE    │+    
 │    ────────────────────   │+    
 │        Aggregates:        │+    
 │        count_star()       │+    
 └─────────────┬─────────────┘+    
 ┌─────────────┴─────────────┐+    
 │         PROJECTION        │+    
 │    ────────────────────   │+    
 │             42            │+    
 │                           │+    
 │          ~0 Rows          │+    
 └─────────────┬─────────────┘+    
 ┌─────────────┴─────────────┐+    
 │       POSTGRES_SCAN       │+    
 │    ────────────────────   │+    
 │          lineitem         │+    
 │                           │+    
 │        Projections:       │+    
 │         l_shipdate        │+    
 │                           │+    
 │          Filters:         │+    
 │ l_shipdate<='1998-08-23': │+    
 │  :DATE AND l_shipdate IS  │+    
 │          NOT NULL         │+    
 │                           │+    
 │          ~0 Rows          │+    
 └───────────────────────────┘+    
     
(1 row)    
```    
    
explain analyze 看到q17 total time 53.22秒       
```    
postgres=# select p from duckdb_proxy($$    
explain analyze select count(*) from lineitem where      
  l_shipdate <= ( date '1998-12-01' - interval '100' day )     
$$) as t (x text, p text);     
    
                                                         p                                                              
--------------------------------------------------------------------------------------------------------------------    
 ┌─────────────────────────────────────┐                                                                           +    
 │┌───────────────────────────────────┐│                                                                           +    
 ││    Query Profiling Information    ││                                                                           +    
 │└───────────────────────────────────┘│                                                                           +    
 └─────────────────────────────────────┘                                                                           +    
 explain analyze select count(*) from lineitem where     l_shipdate <= ( date '1998-12-01' - interval '100' day )  +    
 ┌────────────────────────────────────────────────┐                                                                +    
 │┌──────────────────────────────────────────────┐│                                                                +    
 ││              Total Time: 53.22s              ││                                                                +    
 │└──────────────────────────────────────────────┘│                                                                +    
 └────────────────────────────────────────────────┘                                                                +    
 ┌───────────────────────────┐                                                                                     +    
 │           QUERY           │                                                                                     +    
 └─────────────┬─────────────┘                                                                                     +    
 ┌─────────────┴─────────────┐                                                                                     +    
 │      EXPLAIN_ANALYZE      │                                                                                     +    
 │    ────────────────────   │                                                                                     +    
 │           0 Rows          │                                                                                     +    
 │          (0.00s)          │                                                                                     +    
 └─────────────┬─────────────┘                                                                                     +    
 ┌─────────────┴─────────────┐                                                                                     +    
 │    UNGROUPED_AGGREGATE    │                                                                                     +    
 │    ────────────────────   │                                                                                     +    
 │        Aggregates:        │                                                                                     +    
 │        count_star()       │                                                                                     +    
 │                           │                                                                                     +    
 │           1 Rows          │                                                                                     +    
 │          (0.02s)          │                                                                                     +    
 └─────────────┬─────────────┘                                                                                     +    
 ┌─────────────┴─────────────┐                                                                                     +    
 │         PROJECTION        │                                                                                     +    
 │    ────────────────────   │                                                                                     +    
 │             42            │                                                                                     +    
 │                           │                                                                                     +    
 │       29479362 Rows       │                                                                                     +    
 │          (0.04s)          │                                                                                     +    
 └─────────────┬─────────────┘                                                                                     +    
 ┌─────────────┴─────────────┐                                                                                     +    
 │         TABLE_SCAN        │                                                                                     +    
 │    ────────────────────   │                                                                                     +    
 │          lineitem         │                                                                                     +    
 │                           │                                                                                     +    
 │        Projections:       │                                                                                     +    
 │         l_shipdate        │                                                                                     +    
 │                           │                                                                                     +    
 │          Filters:         │                                                                                     +    
 │ l_shipdate<='1998-08-23': │                                                                                     +    
 │  :DATE AND l_shipdate IS  │                                                                                     +    
 │          NOT NULL         │                                                                                     +    
 │                           │                                                                                     +    
 │       29479362 Rows       │                                                                                     +    
 │          (53.08s)         │                                                                                     +    
 └───────────────────────────┘                                                                                     +    
     
(1 row)    
```    
    
q17本地执行耗时 24秒      
```    
postgres=#   explain analyze select count(*) from lineitem where      
postgres-#   l_shipdate <= ( date '1998-12-01' - interval '100' day );    
                                                                    QUERY PLAN                                                                         
---------------------------------------------------------------------------------------------------------------------------------------------------    
 Finalize Aggregate  (cost=750569.14..750569.15 rows=1 width=8) (actual time=23877.755..23919.287 rows=1 loops=1)    
   ->  Gather  (cost=750568.93..750569.14 rows=2 width=8) (actual time=23872.062..23918.897 rows=3 loops=1)    
         Workers Planned: 2    
         Workers Launched: 2    
         ->  Partial Aggregate  (cost=749568.93..749568.94 rows=1 width=8) (actual time=23816.608..23816.672 rows=1 loops=3)    
               ->  Parallel Seq Scan on lineitem  (cost=0.00..718911.09 rows=12263133 width=0) (actual time=2.255..20950.107 rows=9826454 loops=3)    
                     Filter: (l_shipdate <= '1998-08-23 00:00:00'::timestamp without time zone)    
                     Rows Removed by Filter: 173478    
 Planning Time: 10.225 ms    
 Execution Time: 23921.462 ms    
(10 rows)    
    
Time: 23974.188 ms (00:23.974)    
```    
    
q20 使用duckdb_proxy 56秒, 比本地快很多很多(本地没执行出来)       
```    
select * from duckdb_proxy($$    
select    
  s_name,    
  s_address    
from    
  supplier,    
  nation    
where    
  s_suppkey in (    
    select    
      ps_suppkey    
    from    
      partsupp    
    where    
      ps_partkey in (    
        select    
          p_partkey    
        from    
          part    
        where    
          p_name like 'forest%'    
      )    
      and ps_availqty > (    
        select    
          0.5 * sum(l_quantity)    
        from    
          lineitem    
        where    
          l_partkey = ps_partkey    
          and l_suppkey = ps_suppkey    
          and l_shipdate >= date '1994-01-01'    
          and l_shipdate < date '1994-01-01' + interval '1' year    
      )    
  )    
  and s_nationkey = n_nationkey    
  and n_name = 'CANADA'    
order by    
  s_name;    
$$) as t (s_name text, s_address text);     
```    
    
备注: 目前Linux arm架构版本无法直接install postgres_scanner插件, 需要其他方法安装    
```    
python duckdb extension 安装 (例如 postgres_scanner):      
https://github.com/santosh-d3vpl3x/duckdb_extensions      
https://pypi.org/project/duckdb-extension-postgres-scanner/#files       
    
# pip安装不支持linux arm架构版本, 可以通过编译安装, 如下:     
    
# https://github.com/duckdb/postgres_scanner/    
按说明 build postgres_scanner     
# 打包到某路径     
con = duckdb.connect(database = ':memory:', config = {"allow_unsigned_extensions": "true"})    
con.install_extension('postgres_scanner_path')     
con.load_extension('postgres_scanner_path')     
```    
    
### 3、csv reader      
https://duckdb.org/docs/data/csv/overview       
     
```    
con.execute("""      
CREATE or replace view customer as select * from       
  read_csv('/data/customer.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'c_custkey': 'INTEGER',      
      'c_name': 'VARCHAR(25)',      
      'c_address': 'VARCHAR(40)',      
      'c_nationkey': 'INTEGER',      
      'c_phone': 'CHAR(15)',      
      'c_acctbal': 'DECIMAL(15,2)',      
      'c_mktsegment': 'CHAR(10)',      
      'c_comment': 'VARCHAR(117)'      
    }      
  );      
CREATE or replace view lineitem as select * from       
  read_csv('/data/lineitem.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'l_orderkey': 'INTEGER',      
      'l_partkey': 'INTEGER',      
      'l_suppkey': 'INTEGER',      
      'l_linenumber': 'INTEGER',      
      'l_quantity': 'DECIMAL(15,2)',      
      'l_extendedprice': 'DECIMAL(15,2)',      
      'l_discount': 'DECIMAL(15,2)',      
      'l_tax': 'DECIMAL(15,2)',      
      'l_returnflag': 'CHAR(1)',      
      'l_linestatus': 'CHAR(1)',      
      'l_shipdate': 'DATE',      
      'l_commitdate': 'DATE',      
      'l_receiptdate': 'DATE',      
      'l_shipinstruct': 'CHAR(25)',      
      'l_shipmode': 'CHAR(10)',      
      'l_comment': 'VARCHAR(44)'      
    }      
  );      
CREATE or replace view nation as select * from       
  read_csv('/data/nation.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'n_nationkey': 'INTEGER',      
      'n_name': 'CHAR(25)',      
      'n_regionkey': 'INTEGER',      
      'n_comment': 'VARCHAR(152)'      
    }      
  );      
CREATE or replace view orders as select * from       
  read_csv('/data/orders.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'o_orderkey': 'INTEGER',      
      'o_custkey': 'INTEGER',      
      'o_orderstatus': 'CHAR(1)',      
      'o_totalprice': 'DECIMAL(15,2)',      
      'o_orderdate': 'DATE',      
      'o_orderpriority': 'CHAR(15)',      
      'o_clerk': 'CHAR(15)',      
      'o_shippriority': 'INTEGER',      
      'o_comment': 'VARCHAR(79)'      
    }      
  );      
CREATE or replace view part as select * from       
  read_csv('/data/part.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'p_partkey': 'INTEGER',      
      'p_name': 'VARCHAR(55)',      
      'p_mfgr': 'CHAR(25)',      
      'p_brand': 'CHAR(10)',      
      'p_type': 'VARCHAR(25)',      
      'p_size': 'INTEGER',      
      'p_container': 'CHAR(10)',      
      'p_retailprice': 'DECIMAL(15,2)',      
      'p_comment': 'VARCHAR(23)'      
    }      
  );      
CREATE or replace view partsupp as select * from       
  read_csv('/data/partsupp.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'ps_partkey': 'INTEGER',      
      'ps_suppkey': 'INTEGER',      
      'ps_availqty': 'INTEGER',      
      'ps_supplycost': 'DECIMAL(15,2)',      
      'ps_comment': 'VARCHAR(199)'      
    }      
  );      
CREATE or replace view region as select * from       
  read_csv('/data/region.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      'r_regionkey': 'INTEGER',      
      'r_name': 'CHAR(25)',      
      'r_comment': 'VARCHAR(152)'      
    }      
  );      
CREATE or replace view supplier as select * from       
  read_csv('/data/supplier.tbl',      
    delim = '|',      
    header = false,      
    columns = {      
      's_suppkey': 'INTEGER',      
      's_name': 'CHAR(55)',      
      's_address': 'VARCHAR(40)',      
      's_nationkey': 'INTEGER',      
      's_phone': 'CHAR(15)',      
      's_acctbal': 'DECIMAL(15,2)',      
      's_comment': 'VARCHAR(101)'      
    }      
  );      
""")        
```    
  
### 小结    
上面例子使用plpython3u 写了一个通用函数, 使用这个函数可以将PostgreSQL SQL请求转发给duckdb执行, 加速效果非常明显.     
  
例子中还将csv文件转换为parquet文件, duckdb查询的实际上是parquet文件. 实际上还可以使用duckdb postgres_scanner/csv_reader, 不需要将数据导出到parquet, 对复杂查询性能也有提升.     
  
使用postgres_scanner相比parquet慢、某些请求比本地慢, 原因主要是:     
- 对于要传输较多数据(虽然有pushdown), 并且python DuckDB API没有使用并行fetch     
    - 既然如此, 你可以换其他API试试? 例如GO, C++, C? 反正PolarDB PostgreSQL支持各种PL存储过程语言.      
- postgresql heap table是行存储, 访问少量列大量记录时比parquet 列存储慢    
    
csv 比 parquet 慢的原因     
- csv是行存, parquet是列存     
- csv没有索引, parquet有sort key, min/max statics, bloom filter, 字典等索引信息. csv的过滤性没有parquet好, csv要全扫描, parquet可以过滤.    
    
csv和postgres_scanner哪个快?   
- 主要决定于fetch哪个快, 如果解决了postgres_scanner python duckdb API并行问题, 肯定是postgres_scanner更快(因为这个在PG里还有索引可用). 所以在未来我是看好postgres_scanner的.   
   
为了方案的完整性和通用性, 建议还要考虑  
- 如何“自动的/方便用户有选择的”将数据同步转换为parquet?   
- 结合query rewrite, 让优化器来决定什么时候使用duckdb? 什么时候使用PostgreSQL/PolarDB heap table? 例如基于代价优化选择?   
  
受制于篇幅, 本文没有描写DuckDB本身的优化, 有兴趣的同学也可以关注 https://github.com/digoal/blog 中的相关文章.    
   
同学们还需要了解一下DuckDB为什么在这个场景比PolarDB/PostgreSQL更快? 这些思路如何嫁接到PolarDB/PostgreSQL?     
   
既然可以使用plpython, 那么还能加载什么比duckdb更快的库么?   
- https://umbra-db.com/
- https://velox-lib.io/
  
## 参考  
https://duckdb.org/docs/api/python/reference/    
  
[《PG被DuckDB碾压,该反省哪些方面? DuckDB v0.10.3 在Macmini 2023款上的tpch性能表现如何? PostgreSQL使用duckdb_fdw 的tpch加速性能表现如何?》](../202405/20240525_01.md)    
  
[《qwen2.5-coder真牛~~用它打PolarDB国赛劲劲的》](../202411/20241115_01.md)    
  
[《PolarDB数据库创新设计国赛 - 初赛提交作品指南》](../202410/20241008_04.md)    
  
这篇文章也给了一些思路.   
- [《开源PolarDB|PostgreSQL 应用开发者&DBA 公开课 - 5.7 PolarDB开源版本必学特性 - PolarDB 应用实践实验》](../202401/20240129_01.md)  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
