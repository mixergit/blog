## GPT-o1的开源替代品: reflection     
                                                                                      
### 作者                                                          
digoal                                                          
                                                                 
### 日期                                                               
2024-09-15                                                       
                                                              
### 标签                                                            
PostgreSQL , PolarDB , DuckDB , LLM , 深度思考 , 反射调谐     
                                                                                     
----                                                              
                                                                            
## 背景    
最近o1很火, 看了很多关于o1的介绍, o1有点像人的理性脑, 用时间换取精确性.     
- https://openai.com/index/openai-o1-system-card/  
  
我找到了一个和o1思考模式类似的开源大模型: reflection    
- https://ollama.com/library/reflection  
  
## reflection
  
reflection是一个高性能的模型，用一种叫做反射调谐的新技术训练，教大模型在推理过程中发现错误并纠正。  
  
反射调谐的新训练技术，在给模型的采样数据中，首先在<thinking>和</thinking>标签内输出推理，当模型对其推理满意时，将在<output>和</output>标签内输出最终答案。这些都是特殊的标记，被训练到模型中。  
  
这使模型能够将其内部想法和推理过程从最终响应结果中分离出来，从而改善用户的体验。  
  
在<thinking>部分中，模型可能输出一个或多个<reflection>标记，这表明模型在其推理中捕获了一个错误，并将在提供最终答案之前尝试纠正它。      
  
        
reflection  
  
A high-performing model trained with a new technique called Reflection-tuning that teaches a LLM to detect mistakes in its reasoning and correct course.     
  
Readme  
  
During sampling, the model will start by outputting reasoning inside <thinking> and </thinking> tags, and then once it is satisfied with its reasoning, it will output the final answer inside <output> and </output> tags. Each of these tags are special tokens, trained into the model.  
  
This enables the model to separate its internal thoughts and reasoning from its final answer, improving the experience for the user.  
  
Inside the <thinking> section, the model may output one or more <reflection> tags, which signals the model has caught an error in its reasoning and will attempt to correct it before providing a final answer.  
  
  
除此之外, 在提示词里面也可以让大模型进行深度的思考和自我评估, 实现与o1类似的效果:     
- [《LLMs 在“分类、总结、个性化、结果质量评估”等4个场景的 提示(Prompting)技巧》](../202409/20240914_03.md)      
  
其他参考文章:
- https://blog.langchain.dev/reflection-agents/   鳄鱼脑和理性脑
- https://arxiv.org/abs/2401.02009   反思模型论文
- https://arxiv.org/abs/2303.11366   反思模型论文
- https://zhuanlan.zhihu.com/p/639254455   反思模型论文
- https://www.promptingguide.ai/zh/techniques/reflexion   反思提示(prompting)
- https://reflectionai.ai/     reflection  官网
- [《元提示: 大模型的鳄鱼脑》](../202408/20240815_01.md)  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
