## [转载] Part1: MLX安装与本地环境设置    
                                                                                                
### 作者                                                                    
digoal                                                                    
                                                                           
### 日期                                                                         
2025-01-10                                                          
                                                                        
### 标签                                                                      
PostgreSQL , PolarDB , DuckDB , LLM , MLX , finetuning , 微调 , 大模型 , 蒸馏     
                                                                                               
----                                                                        
                                                                                      
## 背景    
原文:   
- https://www.geekyuncle.com/finetuning-local-llm-with-mlx/  
  
MLX安装和本地环境配置，记录从python版本的兼容性问题，到mlx-examples仓库的简单介绍  
  
# 转载  
  
这篇笔记是以下五个部分中的第1个：[学习笔记：使用 MLX 在 Mac 上微调本地 LLM](../202501/20250110_01.md)。  
  
如果您从头开始此旅程，则需要在 Mac 上设置一些内容才能开始。 如果您已准备好 Python 和 Pip，并安装了MLX代码库，则可以跳到第二步。  
  
## 1、升级Python版本  
我的Mac OS Sonomo中安装的Python版本是3.9，在后续的安装过程中，遇到的最主要问题是SSL版本不兼容的问题：  
```  
Python 3.9.6 (default, Mar 10 2023, 20:16:38)  
[Clang 14.0.3 (clang-1403.0.22.14.1)] on darwin  
Type "help", "copyright", "credits" or "license" for more information.  
  
>>> import openai  
  
Traceback (most recent call last):  
  File "<stdin>", line 1, in <module>  
  File "/Users/yule/Library/Python/3.9/lib/python/site-packages/openai/__init__.py", line 19, in <module>  
    from openai.api_resources import (  
  File "/Users/mic/Library/Python/3.9/lib/python/site-packages/openai/api_resources/__init__.py", line 1, in <module>  
    from openai.api_resources.audio import Audio  # noqa: F401  
  File "/Users/mic/Library/Python/3.9/lib/python/site-packages/openai/api_resources/audio.py", line 4, in <module>  
    from openai import api_requestor, util  
  File "/Users/mic/Library/Python/3.9/lib/python/site-packages/openai/api_requestor.py", line 22, in <module>  
    import requests  
  File "/Users/mic/Library/Python/3.9/lib/python/site-packages/requests/__init__.py", line 43, in <module>  
    import urllib3  
  File "/Users/mic/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py", line 38, in <module>  
    raise ImportError(  
ImportError: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with LibreSSL 2.8.3. See: https://github.com/urllib3/urllib3/issues/2168  
```  
  
因为Python 3.9自带的是SSL库是LibreSSL，而我们需要的urllib3这个库依赖的是OpenSSL 1.1.1以上的版本。这里通常有两种方案：降级安装urllib2，而不是urllib3，或者安装OpenSSL来替换libreSSL。  
  
我的方法是升级安装Python 3.11。从Python 3.10版本开始，会自带OpenSSL新版本，可以避免前面提到的urllib3这个问题。目前最新的Python版本是3.12，而pytorch支持的最高Python版本是3.11，因此，比较安全的做法，是安装Python 3.11。  
- 现在最新是3.13, 我用了3.12的版本, 支持torch没问题.    
  
网上有很多虚拟环境的安装方式，可以让每个项目使用不同的Python版本。由于我的环境相对比较简单，所以就没有使用虚拟环境。直接从[官网](https://www.python.org/downloads/macos/)下载3.11安装包，会自动“升级”原来的3.9版本。这个升级其实并没有删除3.9版本的文件，只是把`/Library/Frameworks/Python.framework/Versions/`目录下的Current软链接切换到了3.11。  
  
升级到 python 3.12  
- https://www.python.org/downloads/macos/     
  
升级python版本, 并配置环境变量    
```  
# 假设已安装到  
/Library/Frameworks/Python.framework/Versions/  
  
$ ll /Library/Frameworks/Python.framework/Versions/  
lrwxr-xr-x   1 root  wheel     4B Jan  8 17:56 Current -> 3.12  
drwxrwxr-x  11 root  admin   352B Jan  8 17:56 3.12  
  
# 添加软链  
ln -s /Library/Frameworks/Python.framework/Versions/Current/bin/pip3 /Library/Frameworks/Python.framework/Versions/Current/bin/pip  
ln -s /Library/Frameworks/Python.framework/Versions/Current/bin/python3 /Library/Frameworks/Python.framework/Versions/Current/bin/python  
  
# 环境变量  
echo "  
export PATH=/Library/Frameworks/Python.framework/Versions/Current/bin:\$PATH  
" >> ~/.bash_profile  
  
# 应用环境变量  
. ~/.bash_profile  
```  
    
把python pip源换成aliyun    
- https://segmentfault.com/a/1190000044200422    
- https://www.jianshu.com/p/71924b5a8aaa    
    
```    
echo "    
[global]    
index-url = https://mirrors.aliyun.com/pypi/simple/    
" > ~/.config/pip/pip.conf    
```    
  
## 2、克隆mlx库到本地  
  
MLX目前有三个相关的库(mlx, mlx-examples, mlx-data)。我们的学习先从样例开始  
```  
git clone --depth 1 https://github.com/ml-explore/mlx-examples.git  
```  
  
## 3、关于mlx-examples  
mlx-examples库中包含了各种使用 MLX 框架的独立示例。  
  
作为学习AI的hello world, [MNIST](https://github.com/ml-explore/mlx-examples/tree/main/mnist) 示例是学习如何使用 MLX 的良好起点。  
  
下面列出了一些更有用的示例。  
  
### 文本模型  
- [Transformer](https://github.com/ml-explore/mlx-examples/tree/main/transformer_lm) 语言模型训练  
- 使用 LLMs 目录中的 [LLaMA](https://github.com/ml-explore/mlx-examples/tree/main/llms/llama)、[Mistral](https://github.com/ml-explore/mlx-examples/tree/main/llms/mistral)、[通义千问](https://github.com/ml-explore/mlx-examples/tree/main/llms/qwen) 等进行大规模文本生成  
- 采用 [Mixtral 8x7B](https://github.com/ml-explore/mlx-examples/tree/main/llms/mixtral) 的专家混合 (MoE) 语言模型  
- 使用 [LoRA 或 QLoRA](https://github.com/ml-explore/mlx-examples/tree/main/lora) 进行参数高效微调  
- 使用 [T5](https://github.com/ml-explore/mlx-examples/tree/main/t5) 的文本到文本多任务 Transformer  
- 使用 [BERT](https://github.com/ml-explore/mlx-examples/tree/main/bert) 进行双向语言理解  
  
### 图像模型  
- 用 [Stable Diffusion](https://github.com/ml-explore/mlx-examples/tree/main/stable_diffusion) 生成图像  
  
### 音频模型  
- 使用 OpenAI 的 [Whisper](https://github.com/ml-explore/mlx-examples/tree/main/whisper) 进行语音识别  
  
### 其他模型  
- 使用 [GCN](https://github.com/ml-explore/mlx-examples/tree/main/gcn) 对图结构数据进行半监督学习  
  
### HuggingFace  
最简单的方式，是使用 [mlx-lm](https://github.com/ml-explore/mlx-examples/tree/main/llms/mlx_lm) 从huggingface上下载各种大模型  
  
可以直接使用以下模型:  
- [mistralai/Mistral-7B-v0.1](https://huggingface.co/mistralai/Mistral-7B-v0.1)  
- [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf)  
- [deepseek-ai/deepseek-coder-6.7b-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct)  
- [01-ai/Yi-6B-Chat](https://huggingface.co/01-ai/Yi-6B-Chat)  
- [microsoft/phi-2](https://huggingface.co/microsoft/phi-2)  
- [mistralai/Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)  
  
绝大多数 [Mistral](https://huggingface.co/models?library=transformers%2Csafetensors&other=mistral&sort=trending), [Llama](https://huggingface.co/models?library=transformers%2Csafetensors&other=llama&sort=trending), [Phi-2](https://huggingface.co/models?library=transformers%2Csafetensors&other=phi&sort=trending) and [Mixtral](https://huggingface.co/models?library=transformers%2Csafetensors&other=mixtral&sort=trending) 风格的模型，应该是开箱可用的。  
  
    
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
