## PostgreSQL 正在挤牙膏? 不, 它在云化           
        
### 作者          
digoal      
          
### 日期            
2024-12-23            
          
### 标签           
PostgreSQL , PolarDB , DuckDB , AIO , queue depth , 适应云     
             
----            
           
## 背景                      
PostgreSQL 正在挤牙膏? 不, 它在云化(适应云)    
  
毫不客气的说: 很多PostgreSQL的最佳实践都是因为PG没有充分发挥块设备的性能, 再不从内核解决这个问题, PostgreSQL就要被云计算时代抛弃了. 例如:    
- 在高并发写的系统中, 频繁更新的表容易膨胀, 建议对频繁更新的系统进行分区. 因为更新是并发的, 而对于单表来说vacuum是单进程的.      
- 在高吞吐写入场景, 建议采用多个表或多个PG实例.  当extendexclusive lock是瓶颈时, 拆表; 当wal 成为瓶颈时拆成多实例.      
     
所有同步IO或一次一个块的读写, 都非常依赖块设备的IO低延迟. 否则就会导致严重的瓶颈.  例如这篇文章的分析：     
- [《一起学PolarDB - 第23期 - 为什么磁盘RT会严重影响vacuum垃圾回收效率?》](../202202/20220216_01.md)    
  
进入云计算时代, 云存储/OSS对象存储成为了存储主流, 主要原因有几个方面:  
- 1、云存储是天然的多副本, 可靠性更高  
- 2、云存储是分布式架构, 弹性更强, 扩缩容更加快捷  
- 3、快照功能. 使得备份、迁移变得更加便利  
- 4、计算和存储分离, 使得多设备可共享云盘, 更利于基于此架构设计存算分离架构应用.
  
  
但是云存储块设备都在远程, OSS对象存储也在远程. 这类存储的IO特征与本地nvme盘截然不同.  具体体现为:    
- 云存储的单次RT很高.   
- 云存储标称的IOPS较高, 但是你得加更大的并发才能把这个标称压测出来. (也就是 Queue depth往往要较大.)     
- 云存储标称的吞吐较大, 但是你得加大并发, 或加大单次IO请求数据的大小才能把标称值压测出来.
- 云存储的顺序IO和离散IO性能几乎无异, 因为底层是分布式块存储.  
  
在使用nvme这种本地低RT、高吞吐、高IOPS的设备时, 前面提到的PG问题并不明显.  但在云计算时代, PostgreSQL上云后问题被放大了, 上云后你的实例最容易遇到的问题可能是:     
- 怎么这么容易膨胀? 不对高频更新表分区的话, 几乎无法避免.     
- 怎么写入速度上不去? (特别是时序类业务, 例如写大量日志.) 开异步wal可以避免这个问题.    
  
幸好PG觉悟了, 正在陆续引入异步IO的底层接口, 上层功能也会陆续支持异步IO. 详见 https://wiki.postgresql.org/wiki/AIO 下面是其中一些功能点的翻译.    
  
### 底层接口变化  
  
#### Read stream API  
  
- **基本缓冲读取流，单对象读取流(relation)** — 已在 v17 中提交。  
- **多对象读取流** — todo。  
    - **场景**：recovery过程加速，对 `CREATE DATABASE ... STRATEGY=WAL_LOG` 也有加速效果。    
  
#### Write stream API  
  
- **基本缓冲写入流** — todo。  
- **驱动 `sync_file_range`** — todo。  
- **驱动 WAL 写入频率** — todo。  
- **绕过缓冲池，适用于 `CREATE INDEX`（批量写入）** — todo。  
  
### 已实现  
  
- **macOS 上的 O_DIRECT**    
  使得 Mac 开发者可以测试 `io_data_direct=on`（工作模式或 `posix_aio` 模式）。  
  
- **`pg_pwritev()` 和 `pg_preadv()`**    
  为同步散播/聚集 I/O 提供可移植支持。  
  
- **使用条件变量替换缓冲 I/O 锁**    
  使得除了从内核提取 I/O 的backends外，其他backends也能等待 I/O 完成。  
  
- **对齐的内存分配**    
  用于direct I/O 中使用的缓冲区的要求。  
  
- **直接 I/O GUC**    
  在 16 版本中作为 `debug_io_direct` 发布，以避免引起过多关注。  
  
- **修复 Windows 上的 `DROP TABLESPACE`（带 `ProcSignalBarrier`）**    
  这是 PostgreSQL 在 Windows 上的一个古老 bug，但之前较难复现；在 `io_method=worker` 下执行 `make check` 每次都会失败，因为进程挂起并持有缓存的文件描述符（fd）。  
  
- **重构relation block extend**    
  允许backend拥有多个处于 `BM_IO_IN_PROGRESS` 状态的缓冲区。  
  
- **流式 I/O，向量化 I/O**    
  引入缓冲区流的概念，最初用于更高效的同步 I/O。  
  
### 使用Read stream的上层功能  
  
- **在 `seq scan` 中使用流式 I/O** — 已在 v17 中实现。  
- **在 `ANALYZE` 中使用流式 I/O** — 已在 v17 中实现。  
- **在 `pg_prewarm` 中使用流式 I/O** — 已在 v17 中实现。  
- **在 `VACUUM` 中使用流式 I/O** — 正在进行中。  
- **在 `bitmap scan` 中使用流式 I/O** — 正在进行中。  
- **与 btree 相关的线程** — todo。  
- **与 brin 相关的线程** — todo。  
- **与 gist 相关的线程** — todo。  
- **与 gin 相关的线程** — todo。  
- **`CREATE DATABASE STRATEGY=WAL_LOG`** — todo。  
  - **recovery database** — todo。  
  
### 使用Write stream的上层功能  
  
- **写数据的地方不多**。  
  
- **`CHECKPOINT`** — 正在进行中。  
- **`CREATE INDEX`（绕过缓冲池，扩展/替换 `bulk_write.c` 功能）** — 正在进行中。  
- **`VACUUM` 写回操作** — 正在进行中。  
- **`COPY` 写回操作** — 正在进行中。  
- **驱逐脏页 写回操作** — 正在进行中。  
  
  
## 参考  
https://wiki.postgresql.org/wiki/AIO  
  
https://anarazel.de/talks/2020-05-28-pgcon-aio/2020-05-28-pgcon-aio.pdf  
     
https://blog.docbert.org/queue-depth-iops-and-latency/  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
