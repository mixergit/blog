## AI论文解读 | The Probabilistic Relevance Framework: BM25 and Beyond   
      
### 作者      
digoal      
      
### 日期      
2025-04-26      
      
### 标签      
PostgreSQL , PolarDB , DuckDB , AI , 论文解读      
      
----      
      
## 背景      
https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf      
      
提示:      
```      
读懂《The Probabilistic Relevance Framework: BM25 and Beyond》这篇论文需要提前掌握哪些基础知识, 请给我讲一下这些基础知识, 尽量通熟易懂, 可以使用markdown支持的图形增加解释性.      
      
通熟易懂的解读《The Probabilistic Relevance Framework: BM25 and Beyond》这篇论文, 关键内容请深入讲解, 可以使用markdown支持的图形增加解释性.      
      
提取《The Probabilistic Relevance Framework: BM25 and Beyond》论文中一些重要的术语并详细解释, 可以使用markdown支持的图形示增加解释性.      
```      
      
## 1 前置知识      
    
好的，为了帮助你理解《The Probabilistic Relevance Framework: BM25 and Beyond》这篇信息检索领域的经典论文，你需要掌握一些基础知识。这篇论文探讨的是如何基于概率理论来对文档进行排序，使其与用户查询更相关，特别是其中著名的 BM25 算法。  
  
下面我将为你梳理这些基础知识，并尽量用通俗易懂的方式解释，辅以简单的图示：  
  
### 1. 信息检索 (Information Retrieval, IR) 基础  
  
* **核心目标**: 从大规模的文档集合（如网页、数据库、图书馆藏书）中，根据用户的**查询 (Query)**，找出**相关 (Relevant)** 的**文档 (Document)**，并将其排序后呈现给用户。  
* **基本流程**:  
    ```mermaid  
    graph LR  
        A[用户输入查询 Query] --> B(搜索引擎/检索系统);  
        B --> C{处理查询 & 匹配文档};  
        C --> D[返回排序后的文档列表 Results];  
    ```  
* **关键概念**:  
    * **文档 (Document)**: 任何可以被检索的信息单元，可以是一篇网页、一封邮件、一本书、一个章节等。  
    * **查询 (Query)**: 用户表达信息需求的关键词或短语。  
    * **语料库 (Corpus)**: 所有待检索文档的集合。  
    * **相关性 (Relevance)**: 一个文档在多大程度上满足了用户查询背后的信息需求。这是 IR 中一个核心且有些主观的概念。  
  
### 2. 概率论基础 (Probability Theory Basics)  
  
这篇论文的核心是概率模型，所以基本的概率概念是必须的。  
  
* **概率 (Probability)**: 表示一个事件发生的可能性大小，通常介于 0 和 1 之间。0 表示不可能发生，1 表示必然发生。  
* **条件概率 (Conditional Probability)**: 在某个事件 B 已经发生的条件下，事件 A 发生的概率。记作 $P(A|B)$。  
    * *例子*: 在“文档包含词语‘苹果’”这个条件下，“文档是关于水果”的概率。  
* **贝叶斯定理 (Bayes' Theorem)**: 这是概率推理的核心，用于根据新的证据更新我们对某个事件发生概率的信念。公式为：  
    $$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$  
    * $P(A|B)$: **后验概率 (Posterior)** - 知道 B 发生后，A 发生的概率。  
    * $P(B|A)$: **似然性 (Likelihood)** - 如果 A 发生，B 发生的概率。  
    * $P(A)$: **先验概率 (Prior)** - 在不知道 B 是否发生时，A 发生的概率。  
    * $P(B)$: **证据 (Evidence)** - B 发生的概率。  
    * *在 IR 中的应用（概念上）*:  
        * $A$: 文档是相关的。  
        * $B$: 文档包含查询词。  
        * 我们想计算 $P(\text{相关}|\text{文档特征})$，即给定文档的特征（如包含哪些词），它有多大概率是相关的。贝叶斯定理提供了一个计算框架。  
  
* **独立性假设 (Independence Assumption)**: 为了简化计算，有时会假设某些事件是相互独立的，即一个事件的发生不影响另一个事件发生的概率。例如，在一些简单的模型中，会假设查询中的词语在文档中出现是相互独立的事件（这在现实中通常不完全成立，但作为简化是有效的）。  
  
### 3. 词频-逆文档频率 (TF-IDF)  
  
虽然 BM25 是概率模型，但它借鉴并改进了 TF-IDF 的思想，理解 TF-IDF 对理解 BM25 的构成很有帮助。  
  
* **词频 (Term Frequency, TF)**: 一个词语在**单个文档**中出现的频率。TF 越高，通常认为这个词对该文档越重要。  
    * *简单想法*: 一个词在一篇文档里出现次数越多，这篇文档就越可能与这个词相关。  
    * *问题*: 像“的”、“是”这种停用词 (Stop Words) 会出现很多次，但意义不大。并且词频的增长不应是线性的（出现 10 次不一定比出现 5 次重要两倍）。  
* **逆文档频率 (Inverse Document Frequency, IDF)**: 一个词语在**整个语料库**中出现的普遍程度的度量。IDF 越高，表示这个词越稀有，区分度越高。  
    $$IDF(t) = \log \frac{N}{df(t)}$$  
    * $N$: 语料库中的文档总数。  
    * $df(t)$: 包含词语 $t$ 的文档数量。  
    * *简单想法*: 如果一个词在很多文档中都出现了（如“的”），它的 IDF 就很低，说明它区分文档的能力弱。如果一个词只在少数几篇文档中出现（如“引力波”），它的 IDF 就很高，说明它对区分这些特定文档很重要。  
* **TF-IDF**: 将 TF 和 IDF 相乘，得到一个词语在特定文档中的重要性权重。  
    $$TFIDF(t, d) = TF(t, d) \times IDF(t)$$  
    * *核心思想*: 一个词在**当前文档**中很重要（TF 高），并且在**所有文档**中比较少见（IDF 高），那么这个词对于这篇文档就非常重要。  
  
    ```mermaid  
    graph TD  
        subgraph TF-IDF 计算
            A[词语 t 在文档 d 中] --> B(计算 TF);  
            A --> C(计算 IDF);  
            B --> D{TF * IDF};  
            C --> D;  
            D --> E[词 t 对文档 d 的重要性权重];  
        end  
  
        subgraph 解释
            F(TF: 词在文档内频率) --越高越重要--> X;  
            G(IDF: 词在语料库中稀有度) --越高越重要--> X;  
            X --结合--> Y(TF-IDF 权重);  
        end  
    ```  
  
### 4. 概率排序原则 (Probability Ranking Principle, PRP)  
  
这是概率相关性框架的理论基石。  
  
* **核心思想**: 为了获得最优的检索效果，系统应该按照文档与用户查询**相关的概率**进行**降序**排序。  
* 也就是说，排名第一的文档应该是系统估计的最可能相关的文档，排名第二的是次可能相关的，以此类推。  
* BM25 等算法就是试图去估计这个“相关概率”（或者与其排序等价的分数）。  
  
### 5. BM25 算法的核心思想 (BM25 Core Ideas)  
  
理解了前面的基础，就可以更好地理解 BM25 了。BM25 本身就是论文的核心内容之一，这里只讲它涉及的基础概念。  
  
* **基于概率**: 它源于概率模型，试图估计文档相关的**几率 (Odds)**，即 $P(\text{相关}|D, Q) / P(\text{不相关}|D, Q)$。  
* **借鉴 TF-IDF**: 它使用了类似 TF 和 IDF 的组件，但对其进行了改进：  
    * **词频饱和度 (Term Frequency Saturation)**: BM25 认识到 TF 的影响不是线性的。一个词从出现 1 次到 2 次，相关性提升可能很明显，但从 100 次到 101 次，提升就微乎其微了。BM25 用一个非线性的函数来处理 TF，使其效果会“饱和”。  
    * **文档长度归一化 (Document Length Normalization)**: 同一个词频，出现在短文档中比出现在长文档中更能说明相关性。BM25 引入了对文档长度的考量和归一化。  
* **参数调整**: BM25 包含一些可调参数（如 $k_1$ 和 $b$），允许根据具体的数据集和应用场景进行优化，以控制 TF 饱和度和文档长度归一化的程度。  
  
### 总结  
  
要读懂《The Probabilistic Relevance Framework: BM25 and Beyond》，你需要：  
  
1.  **了解信息检索的基本目标和流程。**  
2.  **掌握概率论的基本概念，尤其是条件概率和贝叶斯定理。**  
3.  **理解 TF-IDF 的原理及其局限性，因为它为 BM25 提供了基础和对比。**  
4.  **明白概率排序原则是驱动概率模型设计的理论依据。**  
5.  **准备好理解 BM25 如何结合概率思想、改进 TF-IDF 组件（如词频饱和度、文档长度归一化）来计算文档排序分数。**  
  
掌握了这些基础知识后，你就能更容易地理解论文中公式的推导、模型的设计思路以及它相对于早期模型的优势和后续的发展方向（"Beyond"部分）。祝你阅读顺利！  
    
## 2 解读论文      
    
好的，我们来一起深入解读一下这篇在信息检索领域具有里程碑意义的论文（或者说是由 Robertson, Walker, Jones 等人围绕这个框架和 BM25 算法发表的一系列工作）。这篇论文/系列工作不仅提出了一个强大的理论框架，还给出了一个非常实用且效果卓越的搜索排序算法——BM25。  
  
我会按照“理论框架 -> BM25 算法详解 -> 超越与影响”的思路来讲解。  
  
### 1. 概率相关性框架 (The Probabilistic Relevance Framework)  
  
这是整个工作的理论基石。  
  
* **核心思想**: 回归信息检索的本质——找到与用户查询**最相关**的文档。怎么衡量“最相关”？论文提出，应该用**概率**来衡量。  
* **概率排序原则 (Probability Ranking Principle - PRP)**: 这是框架的灵魂。它指出，一个理想的搜索引擎，应该按照文档 $D$ 对于给定查询 $Q$ 的**相关概率 $P(Rel | D, Q)$** 进行**降序**排序。简单说，最可能相关的排在最前面。  
    ```mermaid  
    graph TD  
        A[用户查询 Q] --> B(搜索引擎);  
        B --> C{"计算每个文档 D 的 P(Rel | D, Q)"};  
        C --> D["按 P(Rel | D, Q) 降序排列文档"];  
        D --> E[返回排序结果];  
    ```  
* **如何估计 $P(Rel | D, Q)$**? 直接计算这个概率很困难。研究者们利用**贝叶斯定理**将其转换为更容易处理的形式。他们关注的是**相关性几率 (Odds of Relevance)**：  
    $$Odds(Rel | D, Q) = \frac{P(Rel | D, Q)}{P(NonRel | D, Q)}$$  
    根据贝叶斯定理和一些推导，这个几率可以与文档和查询包含的**词语 (Term)** 联系起来。  
* **早期模型：二元独立模型 (Binary Independence Model - BIM)**:  
    * **假设1 (二元性)**: 文档要么相关 (Relevant)，要么不相关 (Non-relevant)。没有中间状态。  
    * **假设2 (词语独立性)**: 查询中的词语在文档中出现与否是相互独立的事件。（这个假设是为了简化计算，现实中不完全成立，比如 "Hong" 和 "Kong" 经常一起出现）。  
    * 基于这些假设，BIM 推导出文档的相关性几率主要取决于那些**同时出现在查询和文档中**的词语。每个这样的词语 $t$ 会贡献一个**权重**，这个权重反映了该词语区分相关文档和不相关文档的能力。这个权重（称为 Robertson-Sparck Jones Weight 或 Relevance Weight）大致形式如下：  
        $$w_t \approx \log \frac{ P(t | Rel) \times (1 - P(t | NonRel)) }{ P(t | NonRel) \times (1 - P(t | Rel)) }$$  
        * $P(t | Rel)$: 相关文档中包含词语 $t$ 的概率。  
        * $P(t | NonRel)$: 不相关文档中包含词语 $t$ 的概率。  
    * **BIM 的问题**:  
        1.  **需要相关性信息**: 要计算 $w_t$，需要知道哪些文档是相关的，哪些是不相关的，但这正是我们想要通过排序解决的问题！在实际应用中（尤其是第一次查询时），这些信息是未知的。  
        2.  **二元性**: 只考虑词语是否出现，不考虑它出现了多少次（词频 TF），也不考虑文档的长度。这显然丢失了很多信息。  
  
### 2. BM25 算法：从理论到实践的飞跃  
  
BM25 (Best Match 25) 是在概率相关性框架下，对 BIM 进行改进和实践化后诞生的杰出成果。它解决了 BIM 的主要问题，并引入了更符合直觉的启发式因素。  
  
* **目标**: 仍然是估计文档的相关性（或与其排序等价的分数），但要在**没有先验相关性信息**的情况下做到这一点，并且要考虑**词频 (TF)** 和**文档长度 (Document Length)**。  
* **BM25 核心公式**: 对于一个查询 $Q$（包含词语 $q_1, q_2, ..., q_k$）和一个文档 $D$，BM25 的评分函数通常表示为：  
    $$\text{Score}(D, Q) = \sum_{i=1}^{k} \underbrace{\text{IDF}(q_i)}_{\text{部分1: 词语区分度}} \times \underbrace{\frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{avgdl})}}_{\text{部分2: 词频影响与文档长度惩罚}}$$  
    我们来拆解这个公式的关键部分：  
  
    **部分1: IDF (Inverse Document Frequency) - 衡量词语的区分度**  
    * $\text{IDF}(q_i)$: 通常使用类似 $\log \frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}$ 的形式计算。（这里 $N$ 是文档总数，$n(q_i)$ 是包含词语 $q_i$ 的文档数）。  
    * **作用**: 这个部分源于 BIM 中对 $P(t | NonRel)$ 的估计。直观理解是：**一个词语越稀有（在越少的文档中出现），它的 IDF 值就越高，说明它对区分文档越重要，权重就越大。** 常见词（如“的”、“是”）的 IDF 会很低。  
  
    **部分2: 改进的词频项 - 考虑词频饱和度与文档长度**  
    * $f(q_i, D)$: 查询词 $q_i$ 在文档 $D$ 中出现的**频率 (Term Frequency, TF)**。  
    * $|D|$: 文档 $D$ 的**长度**（通常是词语数量）。  
    * $avgdl$: 语料库中所有文档的**平均长度**。  
    * **$k_1$ (正数，通常在 1.2 到 2.0 之间): 控制词频饱和度 (Term Frequency Saturation)**  
        * **作用**: BM25 认识到，TF 对相关性的贡献**不是线性**的。一个词从出现 1 次到 2 次，可能让文档相关性大大增加；但从 100 次增加到 101 次，影响就微乎其微了。$k_1$ 参数就是用来模拟这种“饱和”效应的。  
        * **效果**: $k_1$ 越小，饱和度越高（TF 增长带来的分数提升很快就放缓）；$k_1$ 越大，分数随 TF 增长越接近线性。  
        ```mermaid  
        graph TD  
            subgraph TF 饱和度 k1 控制
                A[低 k1 值] --> B(曲线更早饱和);  
                C[高 k1 值] --> D(曲线更接近线性);  
                E[TF 效果] -- 受 k1 调节 --> F(对最终分数贡献);  
            end  
            %% Conceptual plot description:  
            %% Imagine a plot with TF on x-axis and Score Contribution on y-axis.  
            %% Low k1: Curve rises quickly then flattens out fast.  
            %% High k1: Curve rises more steadily, less flattening.  
        ```  
        ```  
        文本示意图:  
        分数贡献 ^  
               |    /----  (低 k1, 快速饱和)  
               |   /  
               |  /------- (高 k1, 缓慢饱和)  
               | /  
               |/  
               +------------> 词频 (f)  
        ```  
    * **$b$ (0 到 1 之间，通常为 0.75): 控制文档长度归一化 (Document Length Normalization)**  
        * **作用**: 同一个词频，出现在一篇短文档里通常比出现在一篇长文档里更能说明这篇文档的主题与该词相关。$b$ 参数就是用来调节文档长度对评分的影响程度。  
        * **效果**:  
            * $b=0$: 完全不考虑文档长度，长短文档同等对待。  
            * $b=1$: 完全根据文档相对平均长度进行归一化。长文档会受到较大的“惩罚”（或者说短文档获得较大“提升”）。  
            * $b=0.75$ (常用值): 提供一个折中的、比较有效的长度归一化。  
        ```mermaid  
        graph TD  
            subgraph 文档长度归一化 b 控制
                G["文档 D 长度 |D|"] --> H{与平均长度 avgdl 比较};  
                H -- b 值调节 --> I(计算长度惩罚因子);  
                I -- 应用到 TF 项 --> J(影响最终分数);  
                K[b=0] --> L(无长度影响);  
                M[b=1] --> N(强长度影响);  
            end  
  
            %% Conceptual example:  
            %% Doc A (length=50, avgdl=500): Term freq 5. Normalization factor helps boost score.  
            %% Doc B (length=1000, avgdl=500): Term freq 5. Normalization factor helps reduce score relative to Doc A.  
        ```  
        ```  
        文本示意图:  
        假设 TF=5, avgdl=500  
        文档 A (|D|=100):  长度因子 < 1 (惩罚小 / 有提升) -> 分数相对较高  
        文档 B (|D|=1000): 长度因子 > 1 (惩罚大 / 受抑制) -> 分数相对较低  
        (b 越大，这种差异越明显)  
        ```  
  
* **总结 BM25 的优势**:  
    1.  **理论基础**: 源于概率相关性框架，有较好的理论解释。  
    2.  **考虑关键因素**: 同时考虑了词语区分度 (IDF)、词频饱和度 (TF Saturation) 和文档长度。  
    3.  **无需相关性信息**: 可以直接应用于“冷启动”查询。  
    4.  **效果卓越**: 在各种数据集和任务上被证明非常有效，长期作为基准算法。  
    5.  **可调参数**: $k_1$ 和 $b$ 提供了灵活性，可以针对特定场景进行调优。  
  
### 3. "Beyond" BM25 - 超越与影响  
  
论文和后续研究也探讨了 BM25 的局限和发展方向：  
  
* **参数调优**: $k_1$ 和 $b$ 的最优值依赖于具体的数据集和查询类型。通常需要通过在带有标注（哪些文档相关）的测试集上进行实验来找到最佳参数。  
* **局限性**:  
    * **词语独立性假设**: 仍然继承了 BIM 的这个强假设，忽略了词语之间的关系（如短语 "New York"）。  
    * **忽略词语位置/邻近度**: "cat" 和 "dog" 出现在文档的不同位置，与它们紧邻出现，BM25 给出的分数可能差别不大。  
    * **未考虑文档结构**: 标题中的词和正文中的词同等对待。  
    * **未考虑超链接、锚文本** 等 Web 特有的信息。  
* **扩展**:  
    * **BM25F**: 考虑文档结构（如标题、正文、锚文本），给不同字段的词语赋予不同权重。  
    * **结合其他特征**: 可以将 BM25 作为众多特征之一，融入更复杂的机器学习排序模型 (Learning to Rank, LTR) 中。  
    * **查询扩展 (Query Expansion)**: 结合相关性反馈 (Relevance Feedback) 改进查询，再用 BM25 计算。  
* **深远影响**: BM25 成为了信息检索领域**最重要和最广泛使用的基准算法之一**。几乎所有新的排序算法在提出时，都会与 BM25 进行效果比较。它在学术界和工业界（许多搜索引擎的早期或部分模块）都得到了广泛应用。  
  
### 总结  
  
《The Probabilistic Relevance Framework: BM25 and Beyond》这篇/系列论文的核心贡献在于：  
  
1.  **奠定了信息检索中概率排序的理论基础 (PRP)**。  
2.  **推导并提出了 BM25 这一极其成功的实用排序算法**，巧妙地结合了词语的稀有度 (IDF)、词频影响（带饱和度）和文档长度惩罚。  
3.  **启发了后续大量的研究工作**，包括对其本身的改进 (BM25F) 和将其作为更复杂系统的一部分。  
  
理解这篇论文，关键在于掌握概率排序原则的思想，弄清楚 BM25 公式中**每个组成部分（IDF、带 $k_1$ 的 TF 项、带 $b$ 的长度项）的含义和作用**，以及它们是如何近似地实现概率排序原则的目标的。希望这个解读对你有帮助！  
    
## 3 术语      
    
好的，根据您提供的论文标题《The Probabilistic Relevance Framework: BM25 and Beyond》，这是一篇关于信息检索领域经典排序算法 BM25 及其所基于的概率相关性框架的重要论文。  
  
以下是一些该论文中重要的术语及其详细解释：  
  
1.  **概率相关性框架 (Probabilistic Relevance Framework - PRF)**  
    * **核心思想：** 将信息检索问题视为一个概率估计问题。目标是估计文档与查询相关的概率 $P(R=1 | Q, D)$，并根据这个概率对文档进行排序。  
    * **解释：** 传统的检索模型可能基于布尔逻辑或向量空间模型，而 PRF 则从概率的角度出发，认为用户提交查询 $Q$ 是因为存在一个相关文档集合，系统的任务就是预测哪些文档最有可能属于这个集合。PRF 假设文档和查询是随机事件，并试图计算在给定文档 $D$ 和查询 $Q$ 的条件下，文档是相关（$R=1$）或不相关（$R=0$）的概率。  
    * **重要性：** 这是 BM25 的理论基础。BM25 可以看作是 PRF 在特定假设（如二元独立模型 BIM）下的一个实际实现和改进。PRF 提供了一个坚实的数学框架来理解和开发检索模型。  
  
    *图示（概念性）：*  
    ```text  
    +-----------------------+     估计     +-------------------------+  
    | 用户查询 (Q)          | --------> | 文档与查询的相关概率 |  
    | 文档集合中的文档 (D)  |           |      P(R=1 | Q, D)    |  
    +-----------------------+             +-------------------------+  
                                                  |  
                                                  v  
                                        +-----------------+  
                                        | 按概率排序文档  |  
                                        +-----------------+  
    ```  
  
2.  **相关性 (Relevance)**  
    * **核心思想：** 用户对文档与查询之间满足其信息需求的程度的主观判断。  
    * **解释：** 在信息检索中，"相关性" 是最核心的概念。它通常被定义为：文档是否包含了用户提交查询时所寻求的信息，以及这些信息对用户解决问题是否有帮助。PRF 试图量化这种主观的相关性判断的可能性。论文中通常考虑二元相关性（相关 vs. 不相关），尽管实际中可能存在多级相关性。  
    * **重要性：** 整个信息检索系统的目标就是找到并呈现与用户查询最相关的文档。PRF 和 BM25 都是为了更好地预测和衡量这种相关性。  
  
3.  **检索状态值 (Retrieval Status Value - RSV)**  
    * **核心思想：** 由检索模型计算出的、用于衡量文档与查询匹配或相关程度的分数值。  
    * **解释：** 对于给定的查询，检索模型会为文档集合中的每个文档计算一个 RSV。RSV 值越高，表示模型认为该文档与查询越相关。最终的检索结果是按 RSV 值降序排列的文档列表。在 PRF 中，RSV 通常是概率相关性或相关性几率（Odds）的单调函数，例如 $\log \frac{P(R=1 | Q, D)}{P(R=0 | Q, D)}$。  
    * **重要性：** RSV 是检索模型（如 BM25）的输出，直接决定了文档的排序顺序和最终的检索效果。  
  
    *图示（概念性）：*  
    ```markdown  
    +---------------+       计算      +-------+  
    | 查询 (Q)      | --------> | RSV_D |  
    | 文档 (D)      |           +-------+  
    +---------------+  
           |  
           v  
    +---------------------+  
    | 根据 RSV 排序文档   |  
    +---------------------+  
    ```  
  
4.  **词频 (Term Frequency - TF)**  
    * **核心思想：** 查询词在特定文档中出现的次数。  
    * **解释：** 直观上，一个词在文档中出现的次数越多，文档就越可能与该词相关。然而，原始的 TF 有局限性：它没有考虑到文档长度（长文档 TF 更容易高）以及词频达到一定程度后的边际效应递减（一个词出现100次和出现101次的相关性增益可能很小）。BM25 使用了一种非线性的 TF 转换函数来处理这种饱和现象。  
    * **重要性：** TF 是计算文档与查询匹配度的基本特征之一，是 BM25 公式中的核心组成部分。BM25 对 TF 的处理方式（饱和函数和长度归一化结合）是其成功的重要原因。  
  
5.  **逆文档频率 (Inverse Document Frequency - IDF)**  
    * **核心思想：** 衡量一个词在整个文档集合中的稀有程度，用于区分文档。  
    * **解释：** 常见的词（如“的”，“是”）出现在很多文档中，它们对于区分哪些文档更相关帮助不大。而罕见的词通常更具区分度。IDF 对罕见的词赋予更高的权重，对常见的词赋予较低的权重。典型的 IDF 计算公式是 $\log \frac{N}{n_q}$ 或其变体，其中 $N$ 是文档总数，$n_q$ 是包含查询词 $q$ 的文档数。BM25 论文中使用了特定的 IDF 变体。  
    * **重要性：** IDF 是计算词语重要性的另一个核心特征，与 TF 结合使用，构成了大多数现代检索模型的基础（TF-IDF 思路）。它确保了模型能够更好地利用那些具有区分度的词语。  
  
6.  **文档长度归一化 (Document Length Normalization)**  
    * **核心思想：** 调整文档得分，以抵消文档长度对词频的自然影响。  
    * **解释：** 长文档由于词汇总量大，其包含特定查询词的次数（TF）往往比短文档高，即使它们的相关性相同。如果不进行长度归一化，检索系统会倾向于过度偏爱长文档。长度归一化通过将文档的 TF 或总得分与其长度关联起来，来纠正这种偏差。BM25 的归一化方式是将文档长度与其集合中的平均文档长度进行比较。  
    * **重要性：** 这是 BM25 区别于早期模型的一个关键改进。它通过参数 $b$ 来控制归一化的程度，使得 BM25 在处理不同长度文档时更加公平和有效。  
  
7.  **Okapi BM25**  
    * **核心思想：** 一种基于概率相关性框架（特别是从 BIM 演变而来），结合了词频、逆文档频率和文档长度归一化的具体排序函数。  
    * **解释：** 这是论文最核心的内容。BM25 (Best Match 25) 是在 Okapi 系统上开发和测试的一系列排序函数中的一个。它克服了早期 PRF 模型（如 BIM）不考虑词频和文档长度的缺点，通过引入非线性 TF 饱和函数和文档长度归一化，成为了实践中非常有效的排序算法。其基本公式为（略有不同变体）：  
        $$RSV_d = \sum_{q \in Q} IDF(q) \cdot \frac{tf_{q,d} \cdot (k_1 + 1)}{tf_{q,d} + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}$$  
        其中，$Q$ 是查询中的词集合，$q$ 是查询词，$d$ 是文档，$tf_{q,d}$ 是词 $q$ 在文档 $d$ 中的词频，$|d|$ 是文档 $d$ 的长度，$avgdl$ 是文档集合的平均长度，$k_1$ 和 $b$ 是可调参数。  
    * **重要性：** Okapi BM25 是当前信息检索领域中使用最广泛、性能最好的基础排序算法之一。这篇论文详细阐述了它的理论基础、公式构成以及参数的作用。  
  
    *图示（公式结构）：*  
    ```text  
    BM25 Score = SUM over query terms (  
        IDF term * (  
            (TF term * (k1 + 1)) /  
            (TF term + k1 * (  
                (1 - b) + b * (Document Length / Average Document Length)  
            ))  
        )  
    )  
    ```  
    这个图示展示了公式的主要组成部分及其关系。  
  
8.  **参数 (Parameters)** $k_1$ 和 $b$  
    * **核心思想：** BM25 公式中用于调整模型行为的超参数。  
    * **解释：**  
        * **$k_1$**: 控制词频 (TF) 对得分的影响程度，特别是 TF 饱和的速度。$k_1$ 值越大，TF 的影响越大，直到饱和点。通常取值在 1.2 到 2.0 之间。  
        * **$b$**: 控制文档长度归一化的程度。$b=1$ 表示完全长度归一化（得分与文档长度成反比），$b=0$ 表示不进行长度归一化。通常取值在 0.75 左右。  
    * **重要性：** 这些参数使得 BM25 模型可以根据特定的数据集或应用场景进行调优，以获得最佳的检索性能。选择合适的参数值对于 BM25 的效果至关重要。  
  
这些术语是理解《The Probabilistic Relevance Framework: BM25 and Beyond》这篇论文以及 BM25 算法的关键。它们涵盖了 BM25 的理论基础、核心组成部分以及实际应用中的调优方面。  
    
## 参考      
  
https://www.staff.city.ac.uk/~sbrp622/papers/foundations_bm25_review.pdf  
      
<b> 以上内容基于DeepSeek、QwQ及诸多AI生成, 轻微人工调整, 感谢杭州深度求索人工智能、阿里云等公司. </b>      
      
<b> AI 生成的内容请自行辨别正确性, 当然也多了些许踩坑的乐趣, 毕竟冒险是每个男人的天性.  </b>      
      
    
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
