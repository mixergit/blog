## AI论文解读 | BM25 Query Augmentation Learned End-to-End  
  
### 作者  
digoal  
  
### 日期  
2025-04-26  
  
### 标签  
PostgreSQL , PolarDB , DuckDB , AI , 论文解读  
  
----  
  
## 背景  
https://arxiv.org/pdf/2305.14087  
  
提示:  
```  
读懂《BM25 Query Augmentation Learned End-to-End》这篇论文需要提前掌握哪些基础知识, 请给我讲一下这些基础知识, 尽量通熟易懂, 可以使用markdown支持的图形增加解释性.  
  
通熟易懂的解读《BM25 Query Augmentation Learned End-to-End》这篇论文, 关键内容请深入讲解, 可以使用markdown支持的图形增加解释性.  
  
提取《BM25 Query Augmentation Learned End-to-End》论文中一些重要的术语并详细解释, 可以使用markdown支持的图形示增加解释性.  
```  
  
## 1 前置知识  
  
要理解《BM25 Query Augmentation Learned End-to-End》这篇论文，您需要提前掌握以下基础知识：

### 1. 信息检索 (Information Retrieval, IR)

信息检索是指从大量非结构化数据（主要是文本）中查找与用户查询相关的信息的过程。搜索引擎就是最常见的 IR 系统。

### 2. BM25

BM25（Best Matching 25）是一种经典的统计学信息检索排序函数，用于评估文档与查询之间的相关性。它是基于词项频率（Term Frequency, TF）和逆文档频率（Inverse Document Frequency, IDF）的改进。

BM25 的核心思想是：
* 一个词在文档中出现的次数越多（TF越高），该词对文档与查询相关性的贡献越大。
* 一个词在整个文档集合中出现的文档越少（IDF越高，即越稀有），该词区分文档的能力越强，对相关性的贡献也越大。
* BM25 还考虑了文档长度，对过长或过短的文档进行调整。

BM25 的计算公式相对复杂，但其基本原理是通过结合词项的 TF 和 IDF 来计算查询与文档之间的相似度得分  。

### 3. 查询扩展 (Query Augmentation)

查询扩展是指在用户原始查询的基础上，增加新的词项来改进检索结果的技术  。这些新增的词项可以与原始查询词项相关，旨在帮助 IR 系统找到更多相关的文档，解决用户可能使用了同义词或相关概念但未在原始查询中提及的问题。

### 4. 端到端学习 (End-to-End Learning)

端到端学习是一种机器学习的训练方法，模型直接从输入数据学习到输出结果，而无需人工设计中间的特征或步骤。在这篇论文中，意味着查询扩展和重新加权的过程是作为一个整体通过一个模型学习得到的，而不是分成独立的阶段进行处理  。

### 5. 文本表示 (Text Representation)

* **稀疏表示 (Sparse Representation):** 最典型的稀疏表示是词袋模型 (Bag-of-Words, BoW)  。它将文本表示为一个向量，向量的维度是词汇表的大小，向量中的每个元素表示对应词项在文本中出现的频率或是否出现。稀疏表示的向量通常包含很多零。
    例如：查询 "天气 预报"
    词汇表：{"天气", "预报", "北京", "今天"}
    BoW 表示: [1, 1, 0, 0]
* **密集表示 (Dense Representation):** 通过词嵌入（Word Embedding）或神经网络模型（如 BERT）将文本转换为低维度的密集向量。向量中的每个元素都是非零的浮点数，能够捕捉词语之间的语义关系。
    例如：通过 BERT 对 "天气 预报" 生成的向量。

### 6. 神经网络信息检索 (Neural Information Retrieval)

利用深度学习模型和技术来改进信息检索的各个环节，包括查询理解、文档表示、相关性匹配等  。这篇论文就是结合了神经网络方法来改进传统的 BM25。

### 7. BERT 模型 (以及 Transformer 模型)

BERT (Bidirectional Encoder Representations from Transformers) 是一种基于 Transformer 架构的预训练语言模型  。Transformer 是一种神经网络结构，在处理序列数据（如文本）方面表现出色。BERT 及其变体（如 DistilBERT  ）能够学习到词语的上下文信息，生成高质量的词嵌入和句子表示。这篇论文使用了预训练的 BERT 模型作为基础来处理查询  。

### 8. 词项频率 (Term Frequency, TF)

指一个词项在特定文档中出现的次数  。通常会进行归一化处理，以避免长文档有更高的词频。

### 9. 逆文档频率 (Inverse Document Frequency, IDF)

用于衡量一个词项在整个文档集合中的稀有程度  。一个词项在越少的文档中出现，其 IDF 值越高，意味着它越具有区分度。IDF 的常用计算公式为：

$$IDF(w) = \log\frac{N}{df(w)}$$

其中，$N$ 是文档总数，$df(w)$ 是包含词项 $w$ 的文档数。论文中使用了略有不同的平滑版本  。

### 10. 对比损失 (Contrastive Loss)

对比损失是一种机器学习中常用的损失函数，用于训练模型学习区分相似和不相似的样本对  。在信息检索中，通常用于训练模型使得相关文档的得分高于不相关文档的得分  。

### 11. 正则化 (Regularization)

正则化是机器学习中用于防止模型过拟合的技术。L1 正则化是一种常用的正则化方法，它在损失函数中添加模型参数绝对值之和的惩罚项，可以促使模型的一些参数变为零，从而实现特征选择和模型稀疏化  。论文中使用了加权的 L1 正则化来鼓励查询扩展的稀疏性  。

### 12. 分词 (Tokenization)

分词是将文本分解成词项或子词项的过程  。不同的分词方法会影响 IR 系统的性能。WordPiece 是一种常用的子词分词方法，被 BERT 等模型使用  。

理解这些基础知识将有助于您更好地理解论文中提出的 BM25 查询扩展方法如何工作，以及其如何通过端到端学习来优化检索性能。
  
## 2 解读论文  
  
好的，我们来通俗地解读一下《BM25 Query Augmentation Learned End-to-End》这篇论文。

**论文核心思想：**

这篇论文主要探讨了如何在保持传统 BM25 检索方法高效快速的优点的同时，利用深度学习技术来提升其检索效果。核心做法是通过“端到端”的学习方式，让模型自动学习如何“扩展查询词”并“调整词的权重”，从而找到更相关的文档。

**为什么要做这个研究？**

1.  **BM25 的优点与不足：** BM25 是一个经典、高效且内存占用小的检索算法  。在很多场景下，它的表现依然非常具有竞争力  。然而，BM25 主要依赖于词项的精确匹配和统计信息（TF-IDF），容易受到“词汇不匹配”（term mismatch）问题的困扰。比如，查询使用了“汽车”，文档中使用了“车辆”，BM25 可能就无法很好地匹配。
2.  **神经网络 IR 的优点与不足：** 近年来，基于神经网络的信息检索方法取得了很大进展  。这些方法通常能更好地理解查询和文档的语义，解决词汇不匹配问题。但很多神经网络方法（特别是密集检索方法）计算成本高，检索速度慢，且需要大量的内存或磁盘空间  。
3.  **结合两者优点：** 这篇论文的目标就是结合 BM25 的高效性和神经网络的语义理解能力，提出一种既能提高检索精度，又能保持快速检索速度的方法。

**论文提出的方法：端到端学习查询增强和重加权 (End-to-End Learned Query Augmentation and Re-weighting)**

论文提出了一种新颖的方法，不是简单地将神经网络和 BM25 串联使用，而是让神经网络模型学习如何直接**修改** BM25 的查询表示和词项权重。这个学习过程是“端到端”的，意味着模型整体接受训练，目标是优化最终的检索效果。

**核心概念深入讲解：**

1.  **BM25 的向量表示 (BM25's Vector Representation):**
    * 在解释论文的方法之前，需要理解 BM25 可以被看作是查询和文档向量之间的点积。
    * 查询 $q$ 可以用一个二元的词袋向量 $bow(q)$ 表示，向量的每个维度对应词汇表中的一个词，如果词出现在查询中，对应位置为1，否则为0  。
    * 文档 $d$ 可以用一个 BM25 词频向量 $f(d)$ 表示，向量的每个维度对应词汇表中的一个词，其值基于该词在文档中的词频、文档长度和 BM25 的超参数计算得出  。
    * 整个文档集合有一个逆文档频率向量 $v$，每个维度是词汇表中对应词的 IDF 值  。
    * 经典的 BM25 得分可以表示为：$BM25(q, d) = (v \odot bow(q))^\top f(d)$，其中 $\odot$ 表示元素级乘法  。这可以理解为对查询的词袋向量应用 IDF 权重，然后与文档的 BM25 词频向量进行点积。

2.  **查询增强和重加权的数学表示 (Mathematical Representation of Augmentation and Re-weighting):**
    * 论文的核心思想是将查询增强和词项重加权融入到 BM25 的向量表示中。
    * 他们引入了两个向量：
        * **增强向量 $a(q)$:** 这是一个与词汇表大小相同的向量，由神经网络模型根据查询 $q$ 生成  。它可以看作是对原始查询词袋向量 $bow(q)$ 的补充。$a(q)_i$ 的非零值表示词汇表中第 $i$ 个词被“增强”到查询中。通过学习 $a(q)$，模型可以为查询添加新的相关词项。
        * **重加权向量 $w(q)$:** 也是一个与词汇表大小相同的向量，由神经网络模型根据查询 $q$ 生成  。它用于调整每个词项的 IDF 权重。$w(q)_i$ 的值会乘以原始的 $v_i$ 和 $(bow(q)_i + a(q)_i)$，从而改变该词项在最终得分中的贡献。通过学习 $w(q)$，模型可以提升重要词项的权重，降低不重要或噪声词项的权重。
    * 修改后的得分函数为：$score(q, d) = (w(q) \odot v \odot (bow(q) + a(q)))^\top f(d)$  。
    * 这个新的得分函数是可微的  ，这意味着可以通过反向传播和梯度下降等神经网络训练方法来优化生成 $a(q)$ 和 $w(q)$ 的模型参数。

3.  **端到端训练 (End-to-End Training):**
    * 论文使用标准的对比损失函数进行端到端训练  。对比损失的目标是让模型学习区分相关的文档（正例 $d^+$）和不相关的文档（负例 $d^-$）。
    * 损失函数 $\mathcal{L}_{rank} = -\log \frac{\exp(score(q, d^+))}{\sum_{d' \in \mathcal{D}^- \cup \{d^+\}} \exp(score(q, d'))}$  。这个公式鼓励相关文档的得分 $score(q, d^+)$ 远高于负例文档的得分 $score(q, d')$。
    * 通过最小化这个损失，神经网络模型能够学习生成最优的 $a(q)$ 和 $w(q)$，从而使得最终的 BM25 得分更好地反映查询与文档的相关性。

4.  **稀疏性正则化 (Sparsity Regularization):**
    * 为了保持检索效率，论文对增强向量 $a(q)$ 进行了稀疏性正则化  。这意味着模型会被鼓励生成一个包含尽可能多零元素的 $a(q)$ 向量，从而只增强少量对检索有益的词项。
    * 他们发现对出现频率较高的词项施加更大的稀疏性惩罚有助于提升效率和效果  。

5.  **模型架构 (Model Architecture):**
    * 论文使用预训练的 BERT 类编码器（具体是 DistilBERT）来处理查询  。
    * 编码器输出的 [CLS] token 表示用于生成增强向量 $a(q)$，每个查询词项的表示用于生成重加权向量 $w(q)$  。

**为什么称之为“Learned End-to-End”？**

* 传统的查询扩展方法可能是一个独立的步骤，与检索模型分开训练或设计。
* 这篇论文的方法是将生成 $a(q)$ 和 $w(q)$ 的神经网络模型与 BM25 得分函数结合起来，形成一个整体。整个系统从查询输入到最终得分输出，参数通过对比损失进行统一优化。模型直接学习如何调整 BM25 的核心组成部分，以最大化检索效果。

**检索过程 (Retrieval Process):**

* 在检索时，模型首先根据查询 $q$ 生成增强向量 $a(q)$ 和重加权向量 $w(q)$  。
* 然后，根据 $a(q)$ 提取增强后的查询词集 $q \cup \hat{q}$  。
* 同时，计算新的 IDF 向量 $v'$，其元素为 $v'_i = w(q)_i \cdot v_i \cdot (bow(q)_i + a(q)_i)$  。
* 最后，使用标准的 BM25 实现（如 Pyserini）和新的 IDF 向量 $v'$ 来进行文档检索  。这个过程等价于使用修改后的得分函数进行排序。
* 重要的是，这个方法不需要重新编码文档  ，因此可以利用现有的 BM25 索引，保持检索速度。

**实验结果和亮点：**

* 该方法在多个标准信息检索数据集上（如 NQ, MSMARCO, EntityQuestions）都S显著提升了 BM25 的检索性能  。
* 在提高精度的同时，它依然保持了接近原始 BM25 的快速检索速度  。在某些情况下甚至可能更快，因为权重可以使一些词项的贡献变为零  。
* 学习到的增强和重加权参数在不同数据集之间表现出良好的泛化能力（迁移学习）  。这意味着在一个数据集上训练的模型可以直接应用于其他数据集，而无需重新训练。这对于实际应用非常有价值，因为收集大量标注数据进行训练是昂贵的。
* 与一些需要重新编码文档的神经网络方法（如 SPLADE）不同  ，该方法只需修改查询和 IDF 向量，可以无缝集成到现有的稀疏检索框架中  。

**总结：**

这篇论文提出了一种巧妙的方法，通过端到端的学习，让神经网络模型学会如何智能地增强查询和调整词项权重，从而在不牺牲 BM25 检索效率的基础上，显著提升了检索的准确性。其核心在于将神经网络的语义理解能力融入到 BM25 的向量空间中，实现了一种高效且有效的混合检索方法。这个方法为构建更强大、更灵活的稀疏检索系统提供了一个新的思路。
  
## 3 术语  
  
好的，从《BM25 Query Augmentation Learned End-to-End》这篇论文中，我们可以提取出一些重要的术语进行详细解释。理解这些术语是理解论文关键内容的基礎。

1.  **BM25**:
    * **解释**: BM25 (Best Matching 25) 是一种经典的信息检索排序算法，用于计算查询与文档之间的相关性得分。它是基于概率模型的，是 TF-IDF (Term Frequency-Inverse Document Frequency) 的一个高级变种。它考虑了词项在文档中的频率（TF）、词项在整个文档集合中的稀有程度（IDF），以及文档长度。
    * **论文中的作用**: 论文以 BM25 作为基础检索模型，并尝试通过学习的方式来改进它，而不是取代它。论文修改了 BM25 的评分函数，使其能够融入学习到的查询增强和重加权信息。
    * **公式（简化理解）**: BM25 得分不是一个简单的公式，它是一个组合。其核心思想可以概括为：一个词对相关性的贡献随着它在文档中出现次数的增加而增加，但存在饱和；一个词对相关性的贡献随着它在文档集合中出现次数的减少而增加。同时，对不同长度的文档进行归一化处理。
    * **图示**:
        ```mermaid
        graph LR
            A[Query] --> B{BM25 Scoring};
            C[Document] --> B;
            D[Document Collection Statistics] --> B;
            B --> E[Relevance Score];
        ```
        这个图表示 BM25 利用查询、文档和文档集合的统计信息来计算相关性得分。

2.  **查询增强 (Query Augmentation)**:
    * **解释**: 查询增强是指在用户输入的原始查询中添加新的词项。这些新词项通常与原始查询相关，可以帮助检索系统找到更多相关的文档，即使这些文档没有包含原始查询中的所有词。例如，用户搜索“大白菜”，系统可以增强为“大白菜 白菜 青菜 蔬菜”。
    * **论文中的实现**: 论文中，查询增强不是直接添加词项，而是通过学习一个“增强向量” $a(q)$ 来实现的。这个向量与词汇表大小相同，其非零项表示对应的词被“增强”到查询中。这个增强向量是神经网络根据原始查询 $q$ 生成的。
    * **图示**:
        ```mermaid
        graph LR
            A[Original Query] --> B{Learned Augmentation};
            B --> C[Augmented Query Representation];
            C --> D[Improved Retrieval];
        ```
        这个图表示原始查询经过学习到的增强过程，生成一个增强后的查询表示，从而提升检索效果。

3.  **重加权 (Re-weighting)**:
    * **解释**: 重加权是指调整查询中各个词项在计算相关性得分时的重要程度（权重）。在 BM25 中，词项的权重部分由 IDF 决定。通过重加权，可以提升对查询意图更重要的词的权重，降低噪声词或不重要词的权重。
    * **论文中的实现**: 论文通过学习一个“重加权向量” $w(q)$ 来实现。这个向量也是由神经网络根据查询 $q$ 生成的，并用于调整词项在 BM25 得分函数中的权重。具体来说，$w(q)_i$ 会影响词汇表中第 $i$ 个词在最终得分中的贡献。
    * **论文中的得分函数**: 论文修改后的得分函数为 $(w(q) \odot v \odot (bow(q) + a(q)))^\top f(d)$  。这里的 $w(q)$ 就体现了重加权的作用，它与原始的 IDF 向量 $v$ 以及增强后的词袋向量 $(bow(q) + a(q))$ 进行元素级乘法，共同影响最终得分。

4.  **端到端学习 (End-to-End Learning)**:
    * **解释**: 在机器学习中，端到端学习指的是训练一个单一的模型，直接从原始输入（如查询）学习到最终输出（如文档排序得分），而不需要人工设计中间的特征提取或处理步骤。
    * **论文中的意义**: 在这篇论文中，“端到端”意味着生成查询增强向量 $a(q)$ 和重加权向量 $w(q)$ 的神经网络模型是与 BM25 得分函数一起训练的。整个系统作为一个整体，通过优化最终的检索性能（使用对比损失）来调整模型参数。模型直接学习如何生成最优的 $a(q)$ 和 $w(q)$，以提高 BM25 的排序能力。
    * **图示**:
        ```mermaid
        graph LR
            A[Query Input] --> B{Neural Network Model};
            B --> C1["Learned Augmentation a(q)"];
            B --> C2["Learned Re-weighting w(q)"];
            C1 --> D{Modified BM25 Scoring};
            C2 --> D;
            E[Document and Collection Stats] --> D;
            D --> F[Final Score];
            F --> G[Contrastive Loss];
            G --> B;  
        ```
        这个图展示了端到端学习的流程：查询输入到神经网络模型，模型输出 $a(q)$ 和 $w(q)$，这些向量用于修改 BM25 得分，最终的得分用于计算对比损失，损失再反向传播回神经网络，更新模型参数。

5.  **稀疏表示 (Sparse Representation)**:
    * **解释**: 稀疏表示中，向量的大部分元素是零。在文本处理中，词袋模型 (Bag-of-Words) 是一种典型的稀疏表示，向量的维度是词汇表大小，非零元素对应文本中出现的词。
    * **论文中的关联**: BM25 主要基于稀疏的词项表示。论文的方法在保持最终检索过程是稀疏的基础上进行改进。虽然中间学习到的增强向量 $a(q)$ 是密集的，但在检索时会从中提取出非零项对应的词，形成一个增强后的稀疏查询，并结合修改后的稀疏 IDF 向量进行检索。这使得该方法能够利用现有的高效稀疏检索工具（如 Pyserini）。 

6.  **密集表示 (Dense Representation)**:
    * **解释**: 密集表示中，向量的大部分元素是非零的浮点数。通常由神经网络模型（如 BERT）生成，能够捕捉词语和文本的语义信息。
    * **论文中的关联**: 尽管最终的检索是基于稀疏表示，但论文中生成增强向量 $a(q)$ 和重加权向量 $w(q)$ 的神经网络模型（BERT编码器）处理查询时使用了密集的向量表示。这是神经网络捕捉语义能力的关键。论文的方法巧妙地将神经网络学习到的密集信息，“注入”到稀疏的 BM25 框架中。

7.  **对比损失 (Contrastive Loss)**:
    * **解释**: 一种用于训练模型区分正样本对和负样本对的损失函数。在信息检索中，正样本对通常是查询和相关的文档，负样本对是查询和不相关的文档。对比损失的目标是最大化查询与相关文档的相似度得分，同时最小化查询与不相关文档的相似度得分。
    * **论文中的应用**: 论文使用对比损失作为主要的训练目标，来优化生成 $a(q)$ 和 $w(q)$ 的神经网络模型。通过最小化对比损失，模型学习如何生成能够使相关文档在 BM25 修改后的得分中排在前面的 $a(q)$ 和 $w(q)$。

理解了这些术语，您就能更好地把握论文的核心贡献：如何在经典高效的 BM25 框架内，通过神经网络学习到的查询增强和重加权，实现检索性能的提升，同时保持接近原始 BM25 的速度。  
  
## 参考  
  
https://arxiv.org/pdf/2305.14087  
  
<b> 以上内容基于DeepSeek、QwQ及诸多AI生成, 轻微人工调整, 感谢杭州深度求索人工智能、阿里云等公司. </b>  
  
<b> AI 生成的内容请自行辨别正确性, 当然也多了些许踩坑的乐趣, 毕竟冒险是每个男人的天性.  </b>  
  
  
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
