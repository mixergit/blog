## AI论文解读 | Injecting the BM25 Score as Text Improves BERT-Based Re-rankers     
        
### 作者        
digoal        
        
### 日期        
2025-04-26        
        
### 标签        
PostgreSQL , PolarDB , DuckDB , AI , 论文解读        
        
----        
        
## 背景        
https://arxiv.org/pdf/2301.09728        
        
提示:        
```        
读懂《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》这篇论文需要提前掌握哪些基础知识, 请给我讲一下这些基础知识, 尽量通熟易懂, 可以使用markdown支持的图形增加解释性.        
        
通熟易懂的解读《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》这篇论文, 关键内容请深入讲解, 可以使用markdown支持的图形增加解释性.        
        
提取《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》论文中一些重要的术语并详细解释, 可以使用markdown支持的图形示增加解释性.        
```        
        
## 1 前置知识        
      
好的，我们来拆解一下理解这篇论文《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》所需要的基础知识。这篇论文的核心是将一个传统的检索分数（BM25）以一种特别的方式（作为文本）喂给一个现代的深度学习模型（BERT）用于改进排序效果（Re-ranking）。  
  
因此，你需要理解以下几个关键概念：  
  
1.  **信息检索 (Information Retrieval, IR)** 的基本概念  
2.  **BM25 算法** (作为一种经典的检索评分算法)  
3.  **BERT 模型** (作为一种强大的文本表示和理解模型)  
4.  **重排序 (Re-ranking)** 在信息检索中的作用  
  
下面我将尽量通俗易懂地讲解这些基础知识。  
  
-----  
  
### 1\. 信息检索 (Information Retrieval, IR) 的基本概念  
  
想象一下你在搜索引擎（比如百度或 Google）中输入一个查询（Query），然后搜索引擎返回给你一堆相关的文档（Documents）列表。这就是信息检索的过程。  
  
**核心任务：** 从海量文档中找到与用户查询最相关的文档。  
  
**主要步骤（简化）：**  
  
  * **索引 (Indexing):** 提前对所有文档进行处理，建立一个方便快速查找的结构（类似书的索引）。  
  * **匹配/初步检索 (Matching/Initial Retrieval):** 根据用户查询，快速从索引中找出 *可能* 相关的少量文档（比如几百或几千篇），而不是所有文档。这一步追求的是 *速度* 和一定的 *召回率*（尽量不漏掉相关的）。  
  * **排序 (Ranking):** 对这少量 *可能* 相关的文档，根据它们与查询的 *相关性* 进行打分，并按照分数从高到低排列。用户看到的搜索结果就是这个排序后的列表。  
  
**为什么需要 Re-ranking (重排序)？**  
  
初步检索和排序往往使用一些比较快速、但可能不够“聪明”的算法（比如后面要讲的 BM25）。它们主要依赖于词语的匹配。然而，真正的相关性可能涉及更深的语义理解、上下文关系等等，这单靠词语匹配很难做好。  
  
所以，Re-ranking 就出现了。它在初步排序 *之后* 进行，选取初步排序结果中的靠前的一部分文档，然后使用更复杂、更强大的模型（比如 BERT）对这些文档进行更精细的相关性打分和重新排序。  
  
你可以这样理解：  
  
  * **初步排序 (Initial Ranking):** 像图书馆里根据书名或关键词快速找到一堆 *可能* 相关的书。快速但可能不够精确。  
  * **重排序 (Re-ranking):** 像你拿到这堆书后，快速翻阅一下每本书的摘要或目录，更仔细地判断哪本是你 *最需要* 的，然后按照重要程度重新排列。更耗时，但更精确。  
  
*上图简化流程：查询 -\> 初步排序/检索 -\> 候选文档列表 -\> 重排序 -\> 最终排序列表*  
  
-----  
  
### 2\. BM25 算法  
  
BM25 是一种非常经典、也非常有效的初步排序算法。它的全称是 "Okapi BM25"，起源于 Okapi 信息检索系统。  
  
**它做什么？** 它计算一个文档对于给定查询的 *相关性分数*。分数越高，文档越相关。  
  
**它是怎么计算的（核心思想）？**  
  
BM25 主要考虑以下几个因素：  
  
  * **词频 (Term Frequency, TF):** 查询中的词在文档中出现的次数越多，文档越可能相关。  
  * **逆文档频率 (Inverse Document Frequency, IDF):** 查询中的词如果在越少的文档中出现，那么这个词就越能区分文档，因此它在当前文档中出现就越重要。比如，查询“苹果”，词“苹果”在很多文档都出现（水果苹果、公司苹果），IDF就低；但如果查询“苹果股价”，词“股价”出现的文档相对少，IDF就高，说明包含“股价”的文档更可能与查询相关。  
  * **文档长度归一化 (Document Length Normalization):** 长文档有更多机会包含查询词，即使它不太相关。BM25 会对文档长度进行调整，防止长文档天然获得高分。  
  
**简单来说，BM25 的分数是基于查询词在文档中的 *出现频率* 和该词在整个文档集合中的 *稀有程度* 来计算的。**  
  
**优点：** 计算速度快，效果不错，是许多信息检索系统的基石。  
**缺点：** 它是基于词语统计的，不理解词语的意义（同义词、多义词）、语境、词语之间的关系等深层信息。  
  
-----  
  
### 3\. BERT 模型  
  
BERT (Bidirectional Encoder Representations from Transformers) 是一个由 Google 开发的预训练语言模型。它是基于 Transformer 架构的。  
  
**它是什么？** 一个非常大的、在海量文本数据（如维基百科、书籍）上预先训练好的神经网络模型。  
  
**它能做什么？** BERT 学会了理解语言的结构、词语的意义、词语之间的关系以及语境。它可以为词语甚至整个句子生成高质量的数值表示（向量），这些表示包含了丰富的语义信息。  
  
**为什么强大？**  
  
  * **双向理解：** 传统的模型可能只从左到右或从右到左读句子，BERT 可以同时考虑一个词的左边和右边的词来理解它的意思。  
  * **预训练的知识：** 在大量文本上预训练让 BERT 掌握了丰富的语言知识，这些知识可以在特定任务上进行微调（Fine-tuning）。  
  
**BERT 在 Re-ranking 中的应用：**  
  
BERT 可以用来判断一个查询和一个文档之间的 *语义相关性*。通常的做法是将查询和文档拼接起来，然后输入到 BERT 模型中。BERT 的输出可以用来预测这对文本对（查询+文档）的相关性分数。  
  
例如，可以将查询 "apple stock price" 和文档 "Apple Inc. shares rose today..." 输入 BERT，BERT 经过处理后可以输出一个高相关性分数。而将查询 "apple stock price" 和文档 "I ate a delicious apple today..." 输入 BERT，BERT 会输出一个低相关性分数，因为它理解了第一个“apple”是公司，第二个是水果。  
  
**优点：** 能理解深层语义，捕捉词语关系和语境，通常比 BM25 等传统方法在相关性判断上更准确。  
**缺点：** 模型很大，计算量大，速度慢，不适合用于对海量文档进行初步检索。  
  
-----  
  
### 4\. 重排序 (Re-ranking)  
  
前面已经提到过，重排序是信息检索流程中的一个后续步骤。它发生在初步检索之后，目标是对初步检索得到的少量候选文档进行更精确的排序。  
  
**为什么结合 BERT 和 Re-ranking？**  
  
正是因为 BERT 的强大语义理解能力和其计算开销大的特点，它非常适合用于重排序。先用快速的 BM25 筛出大部分不相关的文档，得到一个较小的候选集，然后再用计算更昂贵的 BERT 对这个小集合进行精细排序。这是一种兼顾 *效率* 和 *准确性* 的常见做法。  
  
-----  
  
### 回到论文： Injecting the BM25 Score as Text  
  
现在，我们理解了 BM25 用于初步排序（基于词频和逆文档频率）以及 BERT 用于重排序（基于语义理解）。这篇论文的核心思想就是：  
  
**"BM25 虽然不理解语义，但它的分数反映了词语级别的统计匹配情况，这仍然是相关性的一个重要信号。BERT 虽然理解语义，但它可能没有直接接触到这个词语统计的信号。如果我们将 BM25 的分数 *显式地* 告诉 BERT，BERT 能不能利用这个信息来做得更好？"**  
  
而论文的创新点在于，它不是将 BM25 分数作为一个独立的数值特征输入 BERT（这需要修改 BERT 的输入层），而是将这个 *数值分数* 转换成 *文本*，然后将这个文本信息 *拼接* 到原始的查询和文档文本中，一起输入给 BERT。  
  
例如，如果查询是 "best restaurants near me"，文档 A 的 BM25 分数是 10.5，文档 B 的 BM25 分数是 8.2。  
  
论文的方法可能就是将输入到 BERT 的文本变成类似这样：  
  
  * 对于文档 A: `[CLS] query: best restaurants near me [SEP] document: ... (document A text) ... [SEP] bm25 score: 10.5 [SEP]`  
  * 对于文档 B: `[CLS] query: best restaurants near me [SEP] document: ... (document B text) ... [SEP] bm25 score: 8.2 [SEP]`  
  
通过这种方式，BERT 在处理文本时，也能“看到”并“读懂”BM25 分数这个信息，并学会在做相关性判断时结合利用这个传统信号。论文的结论是，这样做确实提高了 BERT 的重排序性能。  
  
-----  
  
**总结一下，理解这篇论文，你需要掌握的核心基础知识是：**  
  
  * 信息检索的基本流程（特别是初步排序和重排序的区别）。  
  * BM25 算法的核心原理（基于词语统计的相关性打分）。  
  * BERT 模型的基本能力（理解文本语义）。  
  * BERT 如何应用于信息检索的重排序任务。  
  * 理解这篇论文的创新点在于如何巧妙地将 BM25 的统计信息融合到 BERT 的语义处理中。  
  
希望这个解释能帮助你更好地理解这篇论文！  
      
## 2 解读论文        
      
好的，我们来用通俗易懂的方式，深入解读一下这篇论文《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》（将BM25分数作为文本注入可改进基于BERT的重排序器）。  
  
读完这篇论文，你会理解作者们提出了一个**既简单又有效**的方法，来提升搜索引擎中一个关键环节——**重排序**的准确性。  
  
### 论文解决的问题：如何让搜索结果更精准？  
  
我们知道，当你在搜索引擎里输入一个查询词（Query）后，搜索引擎会返回一系列相关的文档（Documents）。这个过程包含两个主要阶段：  
  
1.  **初步检索/粗排 (Initial Retrieval/Ranking):** 从海量文档库中快速找出几百或几千篇 *可能* 相关的文档。这一步追求的是**速度快**和**召回率高**（尽量不漏掉相关的）。常用的算法比如 **BM25** 就很适合做这个。  
2.  **重排序/精排 (Re-ranking):** 对初步筛出的少量文档，进行更精细、更准确的相关性打分，然后重新排列顺序。这一步追求的是**准确性**，确保最相关的文档排在最前面。近年来，强大的深度学习模型，特别是基于 **BERT** 的模型，在这个阶段表现出色。  
  
**问题来了：** BM25 算法很经典，它基于词频、逆文档频率等统计信息来判断相关性，速度快，但它不理解语义，比如它不知道“苹果公司”和“水果苹果”的区别。BERT 模型很“聪明”，能理解语义和上下文，判断相关性更准确，但它运算量大，速度慢，不适合直接处理海量文档。  
  
那么，**有没有办法结合 BM25 的“统计智慧”和 BERT 的“语义智慧”，让重排序做得更好呢？** 这就是这篇论文想要解决的问题。  
  
### 论文的核心思想：把 BM25 分数“告诉”BERT  
  
传统的基于 BERT 的重排序器，通常接收的输入是**查询文本**和**文档文本**。BERT 会学习如何根据这两部分文本来判断它们的相关性。  
  
*传统 BERT 重排序输入示意图：查询文本和文档文本输入给 BERT 模型，输出相关性分数。*  
  
论文作者们的想法非常巧妙：既然 BM25 分数包含了有用的词语统计信息，为什么不把这个信息**显式地**给 BERT 呢？而且，既然 BERT 是个处理**文本**的模型，那我们就把 BM25 的那个**数值分数**转换成**文本**，然后和查询、文档文本一起喂给 BERT！  
  
**这就像什么呢？** 想象你是一位评审员（BERT），正在仔细阅读一份报告（文档）来看它是否符合某个要求（查询）。传统方法是只给你报告内容本身。这篇论文的方法是，除了给你报告内容，还在报告前面附注一行小字：“这份报告的关键词匹配度得分是 [BM25 分数]”。作为一个聪明的评审员（BERT），你就可以参考这个附注的分数，结合报告内容本身，做出更全面的判断。  
  
### 如何把 BM25 分数“作为文本”注入？ (深入讲解关键内容)  
  
这是这篇论文最核心的创新点和关键内容。  
  
标准 BERT 模型接收的输入格式通常是这样的：  
`[CLS] 查询文本 [SEP] 文档文本 [SEP]`  
  
其中，`[CLS]` 是一个特殊的标记，用于表示句子的开始；`[SEP]` 是分隔符，用于分隔不同的文本段。  
  
论文提出的方法是，将 BM25 分数的数值，**简单地**表示成文本，然后加到输入序列的后面。新的输入格式变成这样：  
  
`[CLS] 查询文本 [SEP] 文档文本 [SEP] BM25分数文本 [SEP]`  
  
**“BM25分数文本”具体长什么样？**  
  
非常直观，就是把 BM25 计算出的那个浮点数分数，直接写成字符串形式。比如，如果某个文档的 BM25 分数是 `10.527`，那么加进去的文本可能就是 `"10.527"`，或者更规范一点，带上前缀，比如 `"bm25 score is 10.527"`。  
  
论文中可能试验了不同的表示方法（比如保留多少位小数，是否加前缀等），但核心思想就是把数值**变成字符串**。  
  
*注入 BM25 分数作为文本的 BERT 输入示意图：查询文本、文档文本和 BM25 分数文本一起输入给 BERT 模型，输出相关性分数。*  
  
**这样做的好处：**  
  
1.  **简单易行：** 不需要修改 BERT 模型的内部架构，只需要改变输入数据的预处理方式。这使得这项技术很容易应用到现有的基于 BERT 的重排序系统上。  
2.  **利用 BERT 现有的能力：** BERT 天生就是处理文本的。通过这种方式，BERT 可以利用其强大的文本理解能力来“阅读”和理解 BM25 分数这个信息。它可以学到这个分数代表什么意义，以及如何在判断相关性时结合这个分数。BERT 可能学会，当 BM25 分数很高时，文档很可能是相关的（尽管还要结合语义判断）；当分数很低时，即使语义上有点沾边，可能相关性也不高。  
  
### 实验验证：这种方法真的管用吗？  
  
论文作者们会在标准的信息检索数据集（比如 MS MARCO Ranking Dataset，这是一个常用的、大规模的搜索排序评测数据集）上进行实验来验证他们的方法。  
  
他们会比较：  
  
  * 只使用查询文本和文档文本的**标准 BERT 重排序器**的性能。  
  * 注入了 BM25 分数作为文本的**改进型 BERT 重排序器**的性能。  
  
他们会使用一些标准的评价指标来衡量排序的质量，比如 **nDCG (normalized Discounted Cumulative Gain)**。nDCG 是一个常用的评估搜索结果排序质量的指标，它考虑了文档的相关性级别以及它在列表中的位置（越相关的文档排在越前面，分数越高）。  
  
**实验结果通常表明：**  
  
注入了 BM25 分数作为文本的 BERT 重排序器，在 nDCG 等指标上**取得了性能提升**，表现优于没有注入 BM25 分数的基线模型。这意味着 BERT 确实有效地利用了 BM25 分数这个信息来做出更准确的相关性判断。  
  
**为什么能提升？**  
  
这表明，即使 BERT 已经很强大了，能够理解语义，但传统的、基于词语统计的 BM25 分数仍然包含了 BERT 单纯通过文本阅读可能没有完全捕捉到或重视的有用信息。通过显式地告诉 BERT 这个分数，就好像给了它一个额外的、有价值的线索，帮助它做出更明智的决策。  
  
### 论文的意义和影响  
  
这篇论文的意义在于：  
  
  * 提出了一种**简单而有效**的方法来改进基于 BERT 的信息检索重排序。  
  * 强调了**结合传统统计信息和现代深度学习模型**的潜力。并不是说有了深度学习就完全抛弃传统方法，有时候巧妙地融合能达到更好的效果。  
  * 为将来**将其他类型的结构化信息或分数**注入到大型语言模型中提供了新的思路（不仅仅是 BM25 分数，也许其他特征也可以转化为文本形式）。  
  
总而言之，《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》这篇论文通过一个非常直观且易于实现的技巧——把 BM25 分数变成文本喂给 BERT——成功地提升了 BERT 在信息检索重排序任务上的表现，证明了传统统计信号对于现代深度学习模型仍然具有价值，并且找到了一个巧妙的融合方式。  
      
## 3 术语        
      
好的，我们来提取《Injecting the BM25 Score as Text Improves BERT-Based Re-rankers》这篇论文中的一些重要术语，并进行详细、通俗易懂的解释。理解这些术语，你就掌握了理解论文核心内容的关键。  
  
### 论文重要术语及解释  
  
以下是理解这篇论文最重要的几个术语：  
  
1.  **Information Retrieval (IR) - 信息检索**  
2.  **BM25** (一个核心算法)  
3.  **BERT** (另一个核心模型)  
4.  **Re-ranker / Re-ranking - 重排序** (论文关注的任务)  
5.  **Injecting as Text - 作为文本注入** (论文提出的方法)  
  
我们一个一个详细解释。  
  
---  
  
#### 1. Information Retrieval (IR) - 信息检索  
  
* **通俗解释：** 简单说，信息检索就是“大海捞针”的过程，只不过是要捞的是你需要的信息。最常见的例子就是**搜索引擎**。你输入一个查询，系统从巨大的信息库（互联网上的网页、图书馆的书籍、公司内部文档等）中找到与你的查询相关的、你想要的信息。  
* **在论文中的作用：** 这篇论文研究的问题**属于信息检索领域**。论文提出的方法是为了改进信息检索系统中的一个环节，让搜索结果更准确。所以，理解信息检索的基本目标和流程是理解论文的基础背景。  
* **图形示意：**  
  
    ```mermaid  
    graph LR  
        A(用户查询) --> B(信息检索系统);  
        B --> C(相关信息列表);  
        C --> D(用户);  
    ```  
  
    * 用户输入查询，信息检索系统处理后返回相关信息列表。  
  
---  
  
#### 2. BM25  
  
* **全称：** Best Matching 25 的缩写，起源于 Okapi 信息检索系统。  
* **通俗解释：** BM25 是一种非常经典、计算速度很快的算法，用来衡量一个文档和用户查询之间的**相关性分数**。你可以理解为它是一个“词语匹配度评分员”。  
* **核心原理（简化）：** BM25 主要看查询中的词语在文档中**出现的频率**（越多越可能相关）以及这个词语在整个文档集合中**有多罕见**（越罕见越重要）。它还会考虑文档的长短，避免长文档因为词多而天然得分高。  
* **在信息检索中的作用：** BM25 通常用在信息检索的**初步检索/粗排**阶段。因为它计算快，可以迅速地从海量文档中筛选出几百或几千篇“看着有点像”的文档，形成一个候选集。  
* **在论文中的作用：** **BM25 分数是这篇论文中“被注入”的核心内容**。论文认为 BM25 分数虽然计算简单，但它包含了重要的词语统计信息，这个信息对于判断相关性很有价值。  
* **图形示意：**  
  
    ```mermaid  
    graph LR  
        A(用户查询) --> B(BM25 计算);  
        C(文档内容) --> B;  
        D(整个文档集统计信息) --> B;  
        B --> E(BM25 相关性分数);  
    ```  
  
    * BM25 根据查询、文档内容以及词语在整个文档集里的分布，计算出一个分数。  
  
---  
  
#### 3. BERT  
  
* **全称：** Bidirectional Encoder Representations from Transformers。  
* **通俗解释：** BERT 是一个非常强大、先进的**预训练语言模型**。你可以想象它是一个“语言理解大师”。它在海量的文本数据上学习过，学会了理解语言的语法、语义、上下文以及词语之间的复杂关系。  
* **核心能力：** 能够对文本进行深入的理解和表示，捕捉词语在不同语境下的不同含义。  
* **在信息检索中的作用：** BERT 的强大语义理解能力非常适合用在信息检索的**重排序/精排**阶段。它可以仔细阅读查询和初步筛选出来的文档，理解它们深层的意思是否匹配，从而给出比 BM25 更精准的相关性分数。  
* **在论文中的作用：** **BERT 是这篇论文中“接收注入”的模型**。论文想改进的就是基于 BERT 的重排序器。理解 BERT 的工作方式（特别是它处理文本输入的能力）是理解论文方法的关键。  
* **图形示意：**  
  
    ```mermaid  
    graph LR  
        A(文本输入 - 句子/段落) --> B(BERT 模型);  
        B --> C(文本表示/语义理解结果);  
    ```  
  
    * BERT 接收文本输入，进行复杂的内部处理（基于 Transformer ），输出包含丰富语义信息的表示。  
  
---  
  
#### 4. Re-ranker / Re-ranking - 重排序  
  
* **通俗解释：** 重排序是信息检索流程中的**第二步或后续步骤**。在用快速方法（如 BM25）初步选出一批文档后，重排序器会用更“聪明”但可能更慢的模型（如基于 BERT 的模型）对这些文档进行更细致的评估，然后根据更准确的分数重新排列顺序。  
* **在信息检索中的作用：** 重排序是为了在保证一定处理速度（因为只处理初步筛选出的文档）的同时，提高最终呈现给用户的搜索结果的**准确性和质量**。  
* **在论文中的作用：** **重排序是这篇论文关注的“任务”**。论文提出的方法（注入 BM25 分数作为文本）就是为了**提高基于 BERT 的重排序器的性能**。  
* **图形示意（结合前面概念）：**  
  
    ```mermaid  
    graph LR  
        A(用户查询) --> B(初步排序/BM25);  
        B --> C(候选文档列表);  
        C --> D(重排序器/BERT);  
        D --> E(最终排序列表);  
    ```  
  
    * 用户查询经过 BM25 初步排序得到候选列表，重排序器（这里用 BERT）对候选列表进行更精细的排序，得到最终结果。  
  
---  
  
#### 5. Injecting as Text - 作为文本注入  
  
* **通俗解释：** 这是这篇论文**最创新、最核心的方法**。它指的是把原本是**数值**形式的 BM25 分数，转换成**文本字符串**的形式，然后把这个文本字符串和原始的查询、文档文本**一起作为输入**喂给 BERT 模型。  
* **具体操作：** 比如一个文档的 BM25 分数是 `15.7`，传统的做法可能是试图将这个 `15.7` 作为一个额外的数值特征输入给模型（这可能需要修改模型结构）。而“作为文本注入”的方法是，直接构造一个字符串，比如 `"BM25 score is 15.7"` 或者简单地 `"15.7"`，然后把这个字符串拼接到 BERT 的输入序列中，就像它也是原始文本的一部分一样。  
* **在论文中的作用：** **这是论文提出的主要技术贡献**。论文通过实验证明，BERT 模型能够理解这个被注入的文本形式的 BM25 分数，并利用这个信息来改善自己的判断，从而提高重排序的准确性。这种方法简单有效，不需要改变 BERT 的内部结构。  
* **图形示意（强调输入变化）：**  
  
    ```mermaid  
    graph LR  
        subgraph 传统 BERT 输入
            A1(用户查询文本) --> C1(组合);  
            B1(文档文本) --> C1;  
            C1 --> D1(BERT);  
        end  
        D1 --> E1(相关性分数);  
  
        subgraph 论文提出的输入
            A2(用户查询文本) --> C2(组合);  
            B2(文档文本) --> C2;  
            F2(BM25 分数 -> 文本) --> C2;  
            C2 --> D2(BERT);  
        end  
        D2 --> E2(相关性分数);  
    ```  
  
    * 左边是传统方式：Query 和 Document 组合输入给 BERT。  
    * 右边是论文方法：Query、Document **以及作为文本的 BM25 分数** 一起组合输入给 BERT。BERT 学会同时利用这三部分信息。  
  
---  
  
理解了这五个核心术语及其在信息检索和 BERT 模型中的作用，以及“作为文本注入”这种巧妙的方法，你就基本掌握了这篇论文的关键内容。论文接下来就是通过实验来证明这个“作为文本注入”的方法确实有效，能够提升 BERT 重排序器的性能。  

## 参考        
    
https://arxiv.org/pdf/2301.09728    
        
<b> 以上内容基于DeepSeek、QwQ及诸多AI生成, 轻微人工调整, 感谢杭州深度求索人工智能、阿里云等公司. </b>        
        
<b> AI 生成的内容请自行辨别正确性, 当然也多了些许踩坑的乐趣, 毕竟冒险是每个男人的天性.  </b>        
        
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
