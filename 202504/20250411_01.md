## 大模型(LLM) ACA ACP 通关经验分享   
                                                                                      
### 作者                                                          
digoal                                                          
                                                                 
### 日期                                                               
2025-04-11                                                         
                                                              
### 标签                                                            
PostgreSQL , PolarDB , DuckDB , AI , LLM , 先进生产力工具 , ACA , ACP       
                                                                                     
----                                                              
                                                                            
## 背景       
先人一步掌握先进生产力工具, 是我一次给大学生上入学第一课时分享的第三项基本能力, 有兴趣的同学可以参考:     
- [《德说-第227期, 致大学生的入学第一课》](../202305/20230513_01.md)      
- [《德说-第127期, 人生最重要的事1: 爱与奉献》](../202208/20220822_01.md)      
- [《德说-第126期, 人生最重要的事2: 定位》](../202208/20220819_03.md)      
- [《德说-第100期, 人生最重要的事3: 公理体系》](../202206/20220610_01.md)      
- [《德说-第145期, 人生最重要的事4: 刻意练习》](../202209/20220917_01.md)      
- [《德说-第154期, 人生最重要的事5: 生态思维》](../202210/20221001_03.md)      
- [《德说-第155期, 人生最重要的事6: 格局》](../202210/20221002_01.md)      
- [《德说-第161期, 人生最重要的事7: 知行合一》](../202210/20221021_01.md)      
- [《德说-第173期, 人生最重要的事8: 成象能力》](../202211/20221116_03.md)      
- [《德说-第241期, 人生最重要的事9: 设立目标》](../202306/20230613_01.md)      
    
AI毫无疑问是这个时代的先进生产力工具, 而AI的底层是LLM(大模型)!    
  
花了3天时间把大模型(LLM) ACA ACP 打通关.   
  
不过想考的小伙伴不要误以为这两个认证“很水很好考”, 不是自夸啊我虽然是半桶水但还有点底子. 我对这两个认证的第一印象是学习资料全是干货(有原理、有实践、有真实场景), 而且讲得很有体系和调理, 该深入的知识点讲得也非常透测. 刚好弥补了我这个半桶水之前的不足.   
  
我在考这个认证前对AI的一些底子, 可能包含:    
- 数据库原理和大模型原理及应用实践有一定相通性, 算是能融会贯通吧  
- 我认真仔细的学习过 mistral 的文档(几乎全部, 包括API手册), 以及部分openai的文档   
- 我认真仔细的学习过 ollama 文档(包括ollama github里doc目录里的所有内容)   
- 我翻译过一些 lora 微调的文档, 在Mac上使用MLX框架进行过微调, 对这个项目有一些了解   
- 我自己拿PostgreSQL/PolarDB建过 RAG 里用到的向量数据库, 把我的github里的历史blog全部倒入进去做过测试   
- 把玩过 dify / openWebUI 等支持工作流和chatAgent的开源产品   
- 解读过一系列大模型相关的论文(特别是在DeepSeek R1开源之后)   
- 翻过一些大模型相关的书籍, 例如《神经网络与深度学习》   
- 因为pgvector和阿里云rds pase插件的关系, 很早就对向量数据库还算理解, 包括向量索引结构, 召回和索引优化等.   
- 因为PG的缘故, 对postgresml, pgai, mindsdb等AI相关项目的文档都大概翻阅过
- 研究过Milvus的文档(特别是实践类, 设计到很多大模型的应用场景)  
- 最近则研究过阿里云官网文档里大模型应用相关的部分   
- 一些AI相关产品的使用经验: 如 openapi / huggingface / bailian / cursor / comfui / mcp / qwen / yuanbao / ...   
- 在我的github也写了有上百篇LLM相关文章了.  https://github.com/digoal/blog    
  
所有我的半桶水是真的半桶水, 在学完aca, acp课程后, 很多有疑惑的知识点细节更清晰了, 非常感谢这两门课程.    
  
下面分享一下经验.    
    
## “大模型工程师认证” ACA课程    
    
### 课程地址    
    
https://edu.aliyun.com/course/3126500    
    
### 课程介绍    
这门“大模型工程师认证”ACA课程旨在通过帮助非技术人员、无算法背景的工程技术人员了解大模型的能力，通过一些案例启发思考，助力更多组织在实际生产中应用大模型来提升业务效率、改进产品体验。    
    
### 适合人群    
非技术背景人员：本课程将帮助你发现你的（或者你的客户）业务中有哪些地方可以借助大模型来提效或者增强用户体验，同时帮助你掌握基本概念和部分原理，以便于你跟技术团队合作。    
    
无算法背景的技术人员：你将从本课程了解大模型的能力、以及在业务中落地需要考虑的事情，进而帮助你思考如何通过技术手段帮助业务降本增效、改进产品体验提升竞争力。    
    
任何对大模型感兴趣的初学者：课程中的知识和动手实践，将帮助你思考和挖掘如何借助大模型来提升你的学习、研究或工作效率。    
    
### 你将收获    
了解大模型的基本概念，以便于日后更好的和大模型相关技术人员沟通对话。    
    
了解和思考如何利用大模型来增强产品体验、提升效率，如：构建一个 RAG 私有知识问答机器人。    
    
了解阿里云提供了哪些云服务来帮助你在业务中应用大模型。    
    
### 通关经验    
    
老司机可以裸考, 我这个半桶水都能裸考通关~~    
    
新手建议先看完课程相关学习资料, 不懂的问问大模型, 以下每个课时的知识点总结由AI生成.    
    
### 课时1：认识大模型    
  
1. **大模型定义**：参数规模大（十亿级以上），广泛预训练，适用于多种任务的深度学习模型。    
2. **训练阶段**：    
   • **预训练**：基于海量数据学习通用模式。    
   • **SFT（监督微调）**：针对特定任务的微调。    
   • **RLHF（基于人类反馈的强化学习）**：优化模型输出符合人类偏好。    
3. **特点**：    
   • 参数规模大、适应性强、广泛预训练数据、高计算资源需求。    
4. **分类**：    
   • 按模态：语言模型、多模态模型。    
   • 按应用场景：通用模型、垂直领域模型。    
5. **工作原理**：    
   • **分词化（Tokenization）**：将文本拆分为词、子词或字符。    
   • **自回归生成**：逐步预测下一个词直到生成结束。    
6. **应用场景**：    
   • 通义千问（文本生成）、通义万相（图像/视频生成）、通义灵码（代码开发）、通义法睿（法律服务）等。    
    
### 课时2：大模型的典型应用场景    
    
   
1. **提示词（Prompt）**：用户向大模型提供的文本指令，用于明确任务需求（如问题、请求、描述等）。    
2. **四大应用场景**：    
   • **文本生成**：文案创作、代码生成、影视剧本创作。    
   • **文本编辑**：润色用户反馈、多语言翻译、代码注释。    
   • **总结摘要**：学术文章总结、医疗信息提取。    
   • **推理分析**：法律案件分析、表格数据解读。    
3. **典型应用案例**：    
   • 生成营销文案、跨语言翻译、改写代码、分析财报数据。    
4. **核心目标**：通过优化提示词提升大模型的输出质量。    
    
### 课时3：通过优化提示词来提升回答质量    
    
  
1. **提示词工程定义**：通过优化提示词提升大模型的输出质量，包括明确需求、提供背景、分配角色等。    
2. **五大提示词技巧**：    
   • **直接提问**（零样本提示）：适用于简单明确的任务。    
   • **增加示例**（少样本提示）：通过示例引导模型理解任务格式。    
   • **分配角色**：赋予模型特定身份以生成专业或风格化内容。    
   • **限定输出风格/格式**：指定文本类型、语言风格或结构化输出。    
   • **拆解复杂任务**（思维链提示）：分步骤推理以提高准确性。    
3. **提示词框架要素**：指令、背景信息、示例、输入数据、输出指示。    
4. **推理模型 vs 通用模型**：    
   • 推理模型：专精逻辑推理、数学计算、代码调试，输出包含详细推导步骤。    
   • 通用模型：适用于广泛场景，输出简洁直接。    
5. **推理模型提示技巧**：避免要求逐步思考，直接提问并调整提示词。    
    
### 课时4：借助 API 让大模型自动化地处理任务    
    
  
1. **通义千问API调用**：通过LangChain框架调用API处理批量文本任务，支持分类、分析等操作。    
2. **代码实现流程**：使用Python代码读取Excel文件，逐行调用大模型API处理数据。    
3. **通义灵码辅助开发**：无需编程基础，通过自然语言生成代码，简化API调用流程。    
4. **阿里云大模型API服务**：提供按量付费、多参数规模的模型服务（如`qwen-max`、`qwen2-72b-instruct`）。    
5. **API Key配置**：需在阿里云百炼平台获取API Key并配置到环境变量。    
6. **应用场景扩展**：结合语音转文字模型和大模型实现客服质检等复杂任务。    
    
### 课时5：通过插件增强大模型的能力    
    
   
1. **插件定义**：大模型插件是增强基础模型功能的软件组件，提供实时数据检索、复杂计算、多模态生成等能力。    
2. **插件类型**：    
   • **基础工具**（计算器、时钟、天气查询）    
   • **实时消息插件**（新闻、体育赛事、股票行情）    
   • **功能扩展插件**（代码解释器、图像生成、语音合成）    
3. **插件工作原理**：输入→判断是否需要工具→选择工具→执行工具→整合结果生成回答。    
4. **典型插件应用**：    
   • 计算器插件解决数学问题（如393×285）。    
   • 代码解释器插件实际运行Python代码。    
   • 图片生成插件生成广告图片。    
5. **阿里云插件支持**：    
   • 百炼平台预置插件（计算器、Python解释器、搜索）。    
   • 支持开发自定义插件（如查询阿里云资源）。    
6. **插件开发**：企业可开发内部插件（如查询飞猪API的差旅服务）。    
7. **OpenAI兼容性**：通义千问API支持OpenAI的`function call`，可无缝替换。    
  
### 课时6：通过RAG增强大模型回答原本无法回答的问题    
    
  
1. **RAG定义**：检索增强生成（RAG）通过结合信息检索与大模型生成能力，解决大模型无法直接回答知识库外问题的局限性。    
2. **RAG流程**：    
   • **建立索引**：清洗数据→切分语料块（chunk）→向量化（Embedding）→存储到向量数据库。    
   • **检索生成**：用户问题向量化→检索相似语料块→合并到提示词→大模型生成答案。    
3. **应用案例**：阿里云AI助理基于产品文档构建知识库，解决用户云产品使用问题。    
4. **改进方法**：    
   • **索引优化**：优化文本解析、chunk切分、Embedding模型选择。    
   • **问题理解优化**：多路召回（Multi-Query）、问题分解（Decomposition）、假设答案（HyDE）。    
   • **信息源扩展**：结合互联网搜索（CRAG）、数据库查询（NL2SQL）、知识图谱（Neo4j）。    
   • **答案验证**：Self-RAG通过自省机制验证答案相关性、真实性和完整性。    
5. **评测标准**：检索模块（准确率、召回率）和生成模块（相关性、真实性）的指标设计。    
    
  
### 课时7：借助 Agent 让大模型应用思考、决策并执行任务    
    
   
1. **Agent定义**：基于大语言模型的程序，能通过工具与外部世界交互，具备规划、记忆能力。    
2. **记忆能力**：    
   • **短期记忆**：当前对话历史、工具反馈，受限于模型上下文长度。    
   • **长期记忆**：持久化存储（向量数据库、知识库），用于专业领域回答。    
3. **规划能力**：    
   • **任务分解方法**：思维链（CoT）、思维树（ToT）、ReAct（推理与行动协同）。    
   • **自我反思机制**：验证答案相关性、真实性（如Self-RAG）。    
4. **应用场景**：    
   • 单Agent：自动生成周报、家庭智能助理。    
   • 多Agent（Multi-Agent）：分工协作完成复杂任务（如MetaGPT开发游戏）。    
5. **开发框架**：    
   • **ModelScope-Agent**：支持工具扩展、记忆管理、多模态生成。    
   • **AgentScope**：多Agent协作平台，支持分布式任务、容错机制。    
6. **改进方向**：    
   • 避免输入超长上下文导致的性能下降。    
   • 混合使用不同规格模型（如大模型处理复杂任务，小模型处理简单任务）。    
    
### 课时8：通过微调改善大模型在垂直领域的表现    
  
1. **微调定义**：在预训练模型基础上，使用特定领域数据进一步训练，使其适应特定任务需求。    
2. **微调目标**：    
   • **风格化**：适应特定领域风格（如医疗术语）。    
   • **格式化**：掌握特定系统接口（如API规范）。    
3. **微调优势**：    
   • 提升任务准确率。    
   • 降低推理成本（小模型微调后接近大模型效果）。    
4. **微调关键要素**：    
   • 高质量数据。    
   • 参数配置（避免过拟合/欠拟合）。    
5. **高效微调方法（PEFT）**：    
   • **LoRA**：通过低秩矩阵调整参数，减少训练量。    
   • **Adapter Tuning**：插入适配层，仅训练新增参数。    
   • **Prefix Tuning**：添加虚拟前缀token引导任务。    
   • **Prompt Tuning**：调整输入提示词向量。    
6. **微调流程**：    
   • 数据准备 → 模型选择 → 微调 → 评测 → 部署 → 监控迭代。    
7. **阿里云服务**：    
   • **PAI**：适合技术团队自定义训练。    
   • **百炼**：无代码界面化微调。    
    
### 课时9：大模型应用的安全合规    
    
  
1. **大模型风险类型**：    
   • **个人信息风险**：未经授权的数据收集、隐私泄露（如OpenAI和Google的诉讼案例）。    
   • **内容安全风险**：生成违法/虚假信息、偏见（如BERT性别偏见、ChatGPT虚假案例）。    
   • **模型安全风险**：数据泄露（如GPT-2攻击）、服务中断（如ChatGPT故障）。    
   • **知识产权风险**：训练数据侵权（如Stability AI诉讼）、生成物权属争议（如Stephen Thaler版权案）。    
    
2. **风险来源**：    
   • **训练阶段**：数据来源不合法、未匿名化。    
   • **推理阶段**：用户输入敏感信息、模型生成内容不可控。    
   • **模型缺陷**：算法偏见、鲁棒性不足。    
   • **社会因素**：公众依赖生成内容决策、法律模糊性。    
    
3. **治理策略**：    
   • **个人信息合规**：数据分类分级（阿里云数据安全中心）、去标识化（GB/T 37964）、加密（阿里云加密服务）。    
   • **内容安全保障**：标准回答库（预置答案）、风险识别（阿里云内容审核）、知识检索增强（百炼平台）。    
   • **模型安全防控**：对抗性测试、公平性约束、可解释性规则化。    
   • **知识产权保护**：合法数据获取（购买/开源数据集）、溯源技术（数字水印）、制度革新。    
    
4. **备案要求**：    
   • 《生成式人工智能服务管理暂行办法》要求合规备案（阿里云百炼支持）。    
  
    
### 课时10：拓展学习：多模态大模型、MoE混合专家模型、大小模型云端协同    
   
1. **多模态大模型**：    
   • **定义**：处理多种数据类型（文本、图像、音频等）。    
   • **应用**：文生图（如通义万相）、语音识别（如通义听悟）、视频生成（如悦动人像EMO）。    
   • **挑战**：需多模态表征学习、对齐、融合；资源消耗大。    
2. **混合专家模型（MoE）**：    
   • **核心组件**：专家网络（处理特定任务）和门控网络（分配任务）。    
   • **优势**：高效处理复杂任务，降低训练成本（如Qwen1.5-MoE-A2.7B）。    
   • **局限**：计算资源需求高，过拟合风险。    
3. **大小模型云端协同**：    
   • **大模型特点**：高精度、高资源消耗；**小模型特点**：快速响应、低资源需求。    
   • **协同优势**：资源合理分配，提升响应速度（如电商APP高并发场景）。    
    
### 课时11：学习总结    
   
1. **大模型**：基于海量数据预训练，如通义千问、GPT系列，具备广泛知识。    
2. **Prompting（提示技术）**：通过设计引导语激发模型潜能，无需修改参数。    
3. **RAG（检索增强生成）**：结合检索与生成，解决私域知识问答的幻觉问题。    
4. **微调（Fine-tuning）**：针对特定任务优化模型，需标注数据和计算资源。    
5. **RAG vs 微调**：    
   • RAG：实时更新知识库，输入Token多，推理速度慢。    
   • 微调：风格化生成，输入Token少，训练成本高。    
6. **Agent**：通过工具扩展功能，与外部环境交互的模型应用。    
7. **多模态**：处理文本、图像、音频等跨模态数据，提升复杂场景表现。    
8. **混合专家模型（MoE）**：多个专家网络+门控网络，高效处理复杂任务。    
9. **大小模型协同**：云端大模型处理复杂任务，边缘小模型快速响应。    
10. **使用建议**：耐心、多尝试、持续学习、跨界合作。    
    
## “大模型高级工程师认证” ACP课程    
    
### 课程地址    
    
https://edu.aliyun.com/certification/acp26   
    
### 课程介绍    
阿里云大模型高级工程师ACP认证（Alibaba Cloud Certified Professional - LLM）面向具备编程基础的生成式人工智能技术爱好者和应用开发者们。  
    
### 你将收获    
掌握以下知识与技能：  
- 大模型提示词技巧  
- 检索增强和微调的原理和流程  
- LangChain、Llama-Index和Dify等大模型开发组件的使用方法  
- 工程化评测的概念与方法  
- 大模型的规范和安全性  
  
有能力完成以下任务：  
- 使用阿里云百炼平台构建大模型应用(开发、测评、部署、发布)  
- 使用提示词策略、检索增强、微调技术优化大模型回答质量  
- 使用Multi-agent进行文本、图像、视频等多模态内容生产  
- 能够针对复杂业务场景设计并实施大模型驱动的解决方案  
  
胜任以下岗位：  
- 大模型解决方案高级工程师  
- 大模型应用开发高级工程师  
  
### 内容大纲  
  
主要章节 | 主要内容 | 考察知识点   
---|---|---  
大模型应用开发	| - 通过OpenAI API调用大模型 <br> - 了解大模型的工作原理 | - 基本API参数如model、temperature、top_p等等 <br> - 批量生成与流式生成 <br> - 理解消息与对话历史  
大模型提示词工程 | 构建有效的提示词  | - 提示词框架如提示词要素、提示词分隔符、提示词模板 <br> - 理解系统角色提示词的作用  
 \- | 利用大模型处理各类任务 | - 理解大模型的适用场景 <br>  - 利用大模型开发应用（如批量对员工咨询做意图分类、用大模型做文档审阅、实现针对问题的自动文档修订）  
大模型检索增强 | 通过LlamaIndex构建RAG应用的基本使用方法 | - 理解RAG的核心要素，如文件解析、文本切片、段落召回、段落重排序 <br> - 理解对RAG做召回优化如句子窗口检索、自动合并检索等等  
 \- | 持续优化检索增强能力 | 理解更贴近实战的RAG优化方法如优化文本解析、标题改写优化、表格内容增强、文本分割方法对比等等  
 \- | 对检索增强的能力做自动化评测 | - 了解RAGAS指标体系 <br>  - 懂得RAG系统的评测方法  
大模型的微调 | 微调的概念与要求 | 模型微调的作用、前提、基本步骤、常用算法  
 \- | - 微调的实验与评测 <br>  - 微调数据集构建、微调参数介绍、微调模型评测  
多Agent及多模态应用 | 基于百炼Assistant API构建智能体 | - 理解智能体运行机制 <br> - 掌握用生成多模态内容、构建个性化语音助手等能力  
 \- | 构建更复杂的AI应用 |  - 动手实践阿里发布的AI技术解决方案系列，体验多模态交互技术。 <br> - 了解AI在医疗、教育、娱乐等行业的实际应用。  
生产环境应用实践 | 内容安全合规检查手段 | - 了解大模型开发中存在的内容安全问题 <br> - 了解内容安全合规检测类型及常用方案  
 \- | 大模型应用部署（云服务）安全 |  了解在云服务环境下应用系统安全的基本要素和解决方案  
 \- |  - 在云上部署微调模型的基本方案 <br> - 在云服务如（ECS、FC、PAI）中部署模型 <br> - 在百炼上部署模型 | - 掌握如何使用vLLM进行大模型的部署操作 <br> - 了解如何利用云服务如函数计算（FC）实现AI助手的快速发布    
  
### 通关经验    
  
下面是考试学习资料, 里面有很多小实验.    
- https://github.com/AlibabaCloudDocs/aliyun_acp_learning  
  
强烈推荐开通阿里云百炼大模型服务平台相关的产品进行实际的操作。特别是  
- PAI DSW, 这个是服务器资源(包括一台cpu和一台gpu资源), 和notebook(学习资源都是ipynb文档)  
- 阿里云百炼大模型服务平台, 开通后, 每个模型送100万tokens, 用于完成学习资料中的所有实验. 记得以前写过一篇: [《德说-第316期, AI从业者智商测试: 聪明人在薅羊毛傻子在竞争算力》](../202503/20250329_01.md)    
    - https://bailian.console.aliyun.com/#/home  
- 阿里云通义, 好像实验中用不到   
    - https://tongyi.aliyun.com/   
  
学完课程后先去试一试模拟考, 如果模拟考能满分通过, 并且对学习资料里的知识点没什么疑惑的话就可以去考了, 祝你考试顺利.    
  
     
  
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
  
  
#### [PolarDB 开源数据库](https://openpolardb.com/home "57258f76c37864c6e6d23383d05714ea")
  
  
#### [PolarDB 学习图谱](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
  
  
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
  
  
#### [德哥 / digoal's Github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
  
  
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")
  
  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
  
